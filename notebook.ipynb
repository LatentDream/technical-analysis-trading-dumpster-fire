{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNm8uVJywhbUJG2yk8IoWuW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guthi1/technical-analysis-trading-dumpster-fire/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PolyFinances article"
      ],
      "metadata": {
        "id": "TGZQ-Jkye0BQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO: Explain de situation"
      ],
      "metadata": {
        "id": "F3iLBE-1e3Ns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iF5x7nDEdY9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a61cb00-aac3-4f56-c410-6e8c9e552d42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.8/dist-packages (0.2.12)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.8/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.8/dist-packages (from yfinance) (2.28.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.8/dist-packages (from yfinance) (2.3.5)\n",
            "Requirement already satisfied: cryptography>=3.3.2 in /usr/local/lib/python3.8/dist-packages (from yfinance) (39.0.1)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.8/dist-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.8/dist-packages (from yfinance) (2022.7.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.8/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from html5lib>=1.1->yfinance) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (3.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "# Install required librairy\n",
        "!pip install yfinance\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper function"
      ],
      "metadata": {
        "id": "S5fvPGxxAYZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import contextlib\n",
        "@contextlib.contextmanager\n",
        "def directory(name):\n",
        "  ret = os.getcwd()\n",
        "  os.chdir(name)\n",
        "  yield None\n",
        "  os.chdir(ret)\n",
        "\n",
        "import subprocess\n",
        "def run(input, exception_on_failure=False):\n",
        "  try:\n",
        "    program_output = subprocess.check_output(f\"{input}\", shell=True, universal_newlines=True, stderr=subprocess.STDOUT)\n",
        "  except Exception as e:\n",
        "    if exception_on_failure:\n",
        "      raise e\n",
        "    program_output = e.output\n",
        "\n",
        "    return program_output\n",
        "\n",
        "def runp(input, exception_on_failure=False):\n",
        "    print(input)\n",
        "    print(run(input, exception_on_failure))\n"
      ],
      "metadata": {
        "id": "N492EWD8AXlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "zD_g1JuKfx5z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Params"
      ],
      "metadata": {
        "id": "InaaXZsAAb_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG = False\n",
        "DATA_DIR = \"data/\"\n",
        "DATA_CANDLE = \"data/candle/\"\n",
        "DATA_NORMAL = \"data/normal/\"\n",
        "!mkdir data\n",
        "!mkdir data/candle\n",
        "!mkdir data/normal\n",
        "PRICE_INTERVAL = 2 # In minute, Must be in: 1m,2m,5m,15m,30m,60m,90m\n",
        "WINDOWS_INTERVAL = 60 # In minute, must be > than PRICE_INTERVAL\n",
        "assert WINDOWS_INTERVAL > PRICE_INTERVAL, \"window for analysis must be greater than the price interval\"\n",
        "\n",
        "HOLD = 0\n",
        "BUY = 1\n",
        "SELL = 2"
      ],
      "metadata": {
        "id": "wuce5Hq4ojJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "257e70a7-f23f-4c16-f7f9-414d8a858610"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘data/candle’: File exists\n",
            "mkdir: cannot create directory ‘data/normal’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataset"
      ],
      "metadata": {
        "id": "1KK0lczQoX2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tickers = [\"TSLA\",\"DKNG\", \"PLTR\", \"AMZN\", \"AAPL\", \"F\", \"AMD\", \"NVDA\", \"MARA\", \"NU\", \"NIO\", \"SNAP\", \"GOOGL\", \"SWN\", \"XP\", \"INTC\", \"CCL\", \"GOOG\", \"SOFI\", \"MSFT\", \"T\", \"BAC\", \"UBER\", \"OPEN\", \"AMC\", \"CS\", \"SHOP\", \"DVN\", \"CSCO\", \"META\", \"RIG\", \"DASH\", \"ITUB\", \"AMCR\", \"COIN\", \"RBLX\", \"LUMN\", \"LYFT\", \"AAL\", \"GOLD\", \"KMI\", \"CNNA\", \"XOM\", \"OXY\", \"KGC\", \"OKYO\", \"ROKU\", \"RIOT\", \"PFE\", \"ISEE\", \"PARA\", \"BABA\", \"MRO\", \"GRAB\", \"TOST\", \"SIRI\", \"PBR\", \"UUU\", \"AUY\", \"VALE\", \"KO\", \"RIVN\", \"PCG\", \"STEM\", \"NOK\", \"SI\", \"CMCSA\", \"LU\", \"CTRA\", \"WFC\", \"ET\", \"SOUN\", \"MPW\", \"GM\", \"INZY\", \"SPCE\", \"JNJ\", \"LYNG\", \"CSX\", \"C\", \"TLRY\", \"WMB\", \"FTI\", \"FTCH\", \"DBX\", \"FCX\", \"NCLH\", \"ABNB\", \"COP\", \"SQ\", \"TSM\", \"BMY\", \"BHC\", \"SABR\", \"FSLY\", \"MU\", \"PLUG\", \"CVE\", \"AEM\", \"BAX\", \"KHC\", \"HL\", \"NKLA\", \"QS\", \"PINS\", \"CVX\", \"HAL\", \"DIS\", \"MRK\", \"NEE\", \"EQT\", \"EXC\", \"BKR\", \"TWLO\", \"HOOD\", \"AMAT\", \"SLB\", \"XPEV\", \"HST\", \"DNB\", \"PTON\", \"HBI\", \"X\", \"OSH\", \"MRVL\", \"AR\", \"CLF\", \"NEM\", \"CHPT\", \"ELAN\", \"FUBO\", \"WMT\", \"TTD\", \"BTG\", \"MS\", \"AMAM\", \"CRM\", \"PG\", \"RDFN\", \"BSX\", \"KDP\", \"SNOW\", \"JPM\", \"HPE\", \"PR\", \"MO\", \"CX\", \"U\", \"WU\", \"PPL\", \"YMM\", \"RRC\", \"PDD\", \"LAZR\", \"NWL\", \"KOS\", \"TAL\", \"UAA\", \"MDLZ\", \"CVS\", \"MET\", \"ONEM\", \"CRK\", \"VTRS\", \"ON\", \"NET\", \"UNP\", \"ASX\", \"CHWY\", \"ARR\", \"SBUX\", \"MDT\", \"IQ\", \"UPST\", \"IAG\", \"UMC\", \"STLA\", \"IBN\", \"RITM\", \"NYCB\", \"GGB\", \"CPG\", \"FCEL\", \"RTX\", \"AG\", \"AGNC\"]"
      ],
      "metadata": {
        "id": "UZ8ew8fPRWLg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data\n",
        "data = yf.download(  # or pdr.get_data_yahoo(...\n",
        "        # tickers list or string as well\n",
        "        tickers = tickers,\n",
        "        # use \"period\" instead of start/end\n",
        "        # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
        "        # (optional, default is '1mo')\n",
        "        period = \"5d\",\n",
        "        # fetch data by interval (including intraday if period < 60 days)\n",
        "        # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
        "        interval = f\"{PRICE_INTERVAL}m\",\n",
        "        # group by ticker (to access via data['SPY'])\n",
        "        # (optional, default is 'column')\n",
        "        group_by = 'ticker',\n",
        "        # attempt repair of missing data or currency mixups e.g. $/cents\n",
        "        repair = True,\n",
        "        # use threads for mass downloading\n",
        "        threads = True\n",
        "    )\n",
        "\n",
        "print(f\"Number of row: {len(data)}\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "calvm5Tdd9Ll",
        "outputId": "4f4c72c0-499d-4113-aa57-a88a28c8cd84"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[************          24%                       ]  44 of 186 completedDNB: fixed 1/31 value=0 errors in 2m price data: [Timestamp('2023-02-13 09:30:00-0500', tz='America/New_York')]\n",
            "[*********************100%***********************]  186 of 186 completed\n",
            "\n",
            "1 Failed download:\n",
            "- LYNG: No data found, symbol may be delisted\n",
            "Number of row: 975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            OPEN                                         \\\n",
              "                            Open  High    Low   Close Adj Close  Volume   \n",
              "Datetime                                                                  \n",
              "2023-02-13 09:30:00-05:00  1.960  1.96  1.920  1.9450    1.9450  531675   \n",
              "2023-02-13 09:32:00-05:00  1.945  1.95  1.920  1.9250    1.9250  167402   \n",
              "2023-02-13 09:34:00-05:00  1.930  1.93  1.900  1.9100    1.9100   98648   \n",
              "2023-02-13 09:36:00-05:00  1.905  1.91  1.890  1.9004    1.9004  131508   \n",
              "2023-02-13 09:38:00-05:00  1.905  1.93  1.905  1.9300    1.9300   86498   \n",
              "\n",
              "                                 TSM                                   ...  \\\n",
              "                                Open       High        Low      Close  ...   \n",
              "Datetime                                                               ...   \n",
              "2023-02-13 09:30:00-05:00  95.470001  95.540001  95.099998  95.129997  ...   \n",
              "2023-02-13 09:32:00-05:00  95.099998  95.309998  95.040001  95.105003  ...   \n",
              "2023-02-13 09:34:00-05:00  95.105003  95.150002  94.930000  94.930000  ...   \n",
              "2023-02-13 09:36:00-05:00  94.964996  95.116501  94.910004  95.050003  ...   \n",
              "2023-02-13 09:38:00-05:00  95.040001  95.269997  95.040001  95.205002  ...   \n",
              "\n",
              "                              CX                                   DBX  \\\n",
              "                             Low  Close Adj Close    Volume       Open   \n",
              "Datetime                                                                 \n",
              "2023-02-13 09:30:00-05:00  5.010  5.070     5.070  343481.0  23.700001   \n",
              "2023-02-13 09:32:00-05:00  5.061  5.075     5.075   45508.0  23.745001   \n",
              "2023-02-13 09:34:00-05:00  5.030  5.050     5.050   63214.0  23.700001   \n",
              "2023-02-13 09:36:00-05:00  5.040  5.055     5.055  126112.0  23.680000   \n",
              "2023-02-13 09:38:00-05:00  5.055  5.070     5.070   45652.0  23.670000   \n",
              "\n",
              "                                                                                \n",
              "                                High        Low      Close  Adj Close   Volume  \n",
              "Datetime                                                                        \n",
              "2023-02-13 09:30:00-05:00  23.700001  23.660000  23.690001  23.690001  19443.0  \n",
              "2023-02-13 09:32:00-05:00  23.750000  23.655001  23.695000  23.695000   6411.0  \n",
              "2023-02-13 09:34:00-05:00  23.719999  23.670000  23.670000  23.670000   3524.0  \n",
              "2023-02-13 09:36:00-05:00  23.684999  23.660000  23.670000  23.670000   3659.0  \n",
              "2023-02-13 09:38:00-05:00  23.690001  23.660000  23.690001  23.690001   3567.0  \n",
              "\n",
              "[5 rows x 1116 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65a585d6-3843-43b7-8002-f2e437721b66\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">OPEN</th>\n",
              "      <th colspan=\"4\" halign=\"left\">TSM</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"4\" halign=\"left\">CX</th>\n",
              "      <th colspan=\"6\" halign=\"left\">DBX</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-02-13 09:30:00-05:00</th>\n",
              "      <td>1.960</td>\n",
              "      <td>1.96</td>\n",
              "      <td>1.920</td>\n",
              "      <td>1.9450</td>\n",
              "      <td>1.9450</td>\n",
              "      <td>531675</td>\n",
              "      <td>95.470001</td>\n",
              "      <td>95.540001</td>\n",
              "      <td>95.099998</td>\n",
              "      <td>95.129997</td>\n",
              "      <td>...</td>\n",
              "      <td>5.010</td>\n",
              "      <td>5.070</td>\n",
              "      <td>5.070</td>\n",
              "      <td>343481.0</td>\n",
              "      <td>23.700001</td>\n",
              "      <td>23.700001</td>\n",
              "      <td>23.660000</td>\n",
              "      <td>23.690001</td>\n",
              "      <td>23.690001</td>\n",
              "      <td>19443.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-13 09:32:00-05:00</th>\n",
              "      <td>1.945</td>\n",
              "      <td>1.95</td>\n",
              "      <td>1.920</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>167402</td>\n",
              "      <td>95.099998</td>\n",
              "      <td>95.309998</td>\n",
              "      <td>95.040001</td>\n",
              "      <td>95.105003</td>\n",
              "      <td>...</td>\n",
              "      <td>5.061</td>\n",
              "      <td>5.075</td>\n",
              "      <td>5.075</td>\n",
              "      <td>45508.0</td>\n",
              "      <td>23.745001</td>\n",
              "      <td>23.750000</td>\n",
              "      <td>23.655001</td>\n",
              "      <td>23.695000</td>\n",
              "      <td>23.695000</td>\n",
              "      <td>6411.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-13 09:34:00-05:00</th>\n",
              "      <td>1.930</td>\n",
              "      <td>1.93</td>\n",
              "      <td>1.900</td>\n",
              "      <td>1.9100</td>\n",
              "      <td>1.9100</td>\n",
              "      <td>98648</td>\n",
              "      <td>95.105003</td>\n",
              "      <td>95.150002</td>\n",
              "      <td>94.930000</td>\n",
              "      <td>94.930000</td>\n",
              "      <td>...</td>\n",
              "      <td>5.030</td>\n",
              "      <td>5.050</td>\n",
              "      <td>5.050</td>\n",
              "      <td>63214.0</td>\n",
              "      <td>23.700001</td>\n",
              "      <td>23.719999</td>\n",
              "      <td>23.670000</td>\n",
              "      <td>23.670000</td>\n",
              "      <td>23.670000</td>\n",
              "      <td>3524.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-13 09:36:00-05:00</th>\n",
              "      <td>1.905</td>\n",
              "      <td>1.91</td>\n",
              "      <td>1.890</td>\n",
              "      <td>1.9004</td>\n",
              "      <td>1.9004</td>\n",
              "      <td>131508</td>\n",
              "      <td>94.964996</td>\n",
              "      <td>95.116501</td>\n",
              "      <td>94.910004</td>\n",
              "      <td>95.050003</td>\n",
              "      <td>...</td>\n",
              "      <td>5.040</td>\n",
              "      <td>5.055</td>\n",
              "      <td>5.055</td>\n",
              "      <td>126112.0</td>\n",
              "      <td>23.680000</td>\n",
              "      <td>23.684999</td>\n",
              "      <td>23.660000</td>\n",
              "      <td>23.670000</td>\n",
              "      <td>23.670000</td>\n",
              "      <td>3659.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-13 09:38:00-05:00</th>\n",
              "      <td>1.905</td>\n",
              "      <td>1.93</td>\n",
              "      <td>1.905</td>\n",
              "      <td>1.9300</td>\n",
              "      <td>1.9300</td>\n",
              "      <td>86498</td>\n",
              "      <td>95.040001</td>\n",
              "      <td>95.269997</td>\n",
              "      <td>95.040001</td>\n",
              "      <td>95.205002</td>\n",
              "      <td>...</td>\n",
              "      <td>5.055</td>\n",
              "      <td>5.070</td>\n",
              "      <td>5.070</td>\n",
              "      <td>45652.0</td>\n",
              "      <td>23.670000</td>\n",
              "      <td>23.690001</td>\n",
              "      <td>23.660000</td>\n",
              "      <td>23.690001</td>\n",
              "      <td>23.690001</td>\n",
              "      <td>3567.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1116 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65a585d6-3843-43b7-8002-f2e437721b66')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65a585d6-3843-43b7-8002-f2e437721b66 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65a585d6-3843-43b7-8002-f2e437721b66');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build dataset"
      ],
      "metadata": {
        "id": "40KdeKTSD948"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_number = 0\n",
        "# Dataframe to save the value we need\n",
        "dataset={\"candle_path\": [], \"normal_path\": [], \"action\": [], \"info\": [], \"filename\": []}"
      ],
      "metadata": {
        "id": "TmFepAAuGoKt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try it for ford first\n",
        "for ticker in tqdm(tickers):\n",
        "    ticker_data = data[ticker].copy(deep=True)\n",
        "    ticker_data.dropna() # Sanity check\n",
        "    ticker_data[\"datetime\"] = ticker_data.index\n",
        "\n",
        "    # Find Dataset range\n",
        "    day = ticker_data['datetime'].min()\n",
        "    last_end = ticker_data['datetime'].max()\n",
        "    if DEBUG: print(f\"From {day} to {last_end}\")\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "    while day <= last_end:\n",
        "        if DEBUG: print(f\"{day}\")\n",
        "\n",
        "        start_window = day\n",
        "        end_window = start_window + datetime.timedelta(minutes=WINDOWS_INTERVAL)\n",
        "        end_of_day = day + datetime.timedelta(hours=6.5)\n",
        "\n",
        "        while start_window < end_of_day - datetime.timedelta(minutes=WINDOWS_INTERVAL):\n",
        "            if DEBUG: print(f\"    {start_window}\")\n",
        "\n",
        "            # Create a mask for the desired window\n",
        "            mask = (ticker_data['datetime'] > start_window) & (ticker_data['datetime'] <= end_window)\n",
        "            window_data = ticker_data.loc[mask]\n",
        "            \"\"\" TODO: This could be change to something smarter \"\"\"\n",
        "            mean_close = window_data.Close.mean()\n",
        "\n",
        "            # \"up\" dataframe will store the stock_prices when the closing stock \n",
        "            # price is greater than or equal to the opening stock prices\n",
        "            up = window_data[window_data.Close >= window_data.Open]\n",
        "            col1 = 'red'\n",
        "\n",
        "            # \"down\" dataframe will store the stock_prices when the closing stock \n",
        "            # price is lesser than the opening stock prices\n",
        "            down = window_data[window_data.Close < window_data.Open]\n",
        "            col2 = 'blue'\n",
        "\n",
        "            # Setting width of candlestick elements\n",
        "            width = .0005\n",
        "            width2 = .00008\n",
        "\n",
        "            # Plotting up prices of the stock\n",
        "            plt.bar(up.datetime, up.Close-up.Open, width, bottom=up.Open, color=col1)\n",
        "            plt.bar(up.datetime, up.High-up.Close, width2, bottom=up.Close, color=col1)\n",
        "            plt.bar(up.datetime, up.Low-up.Open, width2, bottom=up.Open, color=col1)\n",
        "\n",
        "            # Plotting down prices of the stock\n",
        "            plt.bar(down.datetime, down.Close-down.Open, width, bottom=down.Open, color=col2)\n",
        "            plt.bar(down.datetime, down.High-down.Open, width2, bottom=down.Open, color=col2)\n",
        "            plt.bar(down.datetime, down.Low-down.Close, width2, bottom=down.Close, color=col2)\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Saving the candle plot\n",
        "            plt_name = f\"{plot_number}.png\"\n",
        "            plt.savefig(f\"{DATA_CANDLE}{plt_name}_{ticker}\", format=\"png\")\n",
        "            plt.close()    \n",
        "            dataset[\"filename\"].append(plt_name)\n",
        "            dataset[\"candle_path\"].append(DATA_CANDLE)\n",
        "\n",
        "            # Plotting the time series of given dataframe\n",
        "            plt.plot(window_data[\"datetime\"], window_data[\"Adj Close\"])\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Saving the normal plot\n",
        "            # plt_name = f\"{DATA_NORMAL}{plot_number}_{ticker}.png\"\n",
        "            # plt.savefig(plt_name, format=\"png\")\n",
        "            # plt.close()    \n",
        "            # dataset[\"normal_path\"].append(DATA_CANDLE)\n",
        "            \n",
        "            # Update var\n",
        "            plot_number += 1\n",
        "            start_window = end_window\n",
        "            end_window = start_window + datetime.timedelta(minutes=WINDOWS_INTERVAL)\n",
        "\n",
        "            # Check if it's a hold, buy and sold\n",
        "            \"\"\" TODO: This could be change to something smarter \"\"\"\n",
        "            mask = (ticker_data['datetime'] > start_window) & (ticker_data['datetime'] <= end_window)\n",
        "            window_data = ticker_data.loc[mask]\n",
        "            mean_close_next_interval = window_data.Close.mean()\n",
        "\n",
        "            diff = mean_close_next_interval / mean_close\n",
        "            if diff > 1.002:\n",
        "                dataset[\"action\"].append(BUY)\n",
        "            elif diff < 0.998:\n",
        "                dataset[\"action\"].append(SELL)\n",
        "            else:\n",
        "                dataset[\"action\"].append(HOLD)\n",
        "\n",
        "            # For debugging later\n",
        "            dataset[\"info\"].append(f\"{ticker}: {start_window}\")\n",
        "\n",
        "        day += datetime.timedelta(days=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy7tT02qyNNq",
        "outputId": "39b598cb-71e4-477d-b430-8673dcdb44e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 171/186 [15:41<01:12,  4.84s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.DataFrame(data=dataset)\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "pLxH4U3nFKii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save or open data"
      ],
      "metadata": {
        "id": "z3OhLQl0A6UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_csv(\"data/dataset.csv\")"
      ],
      "metadata": {
        "id": "O8KgSGtE_n3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runp(\"zip -r /content/data.zip /content/data\")\n",
        "from google.colab import files\n",
        "files.download(\"/content/data.zip\")"
      ],
      "metadata": {
        "id": "vK68SUM9AnQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runp(f\"unzip -q /content/data.zip\")"
      ],
      "metadata": {
        "id": "pN_uaam__x_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "PCYx7Z2UHTED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.io import read_image\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Fix random seed\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "k3eRQkNiIeqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a data loader for the dataset we created"
      ],
      "metadata": {
        "id": "GOlnoVvLI4Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TechnicalAnalysisDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, chart_dir, transform=None):\n",
        "        self.df = data\n",
        "        self.img_dir = chart_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.df.iloc[idx][\"filename\"])\n",
        "        image = read_image(img_path)\n",
        "        image = image / 255\n",
        "        label = self.df.iloc[idx][\"action\"]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "fa2N7CRBI6J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our dataset, we will need to split it in a training and validation set and we will need a data loader to be able to have minibatch."
      ],
      "metadata": {
        "id": "g_JWp5T3Sfdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(df, frac=0.2):\n",
        "    \n",
        "    # get random sample \n",
        "    test = df.sample(frac=frac, axis=0)\n",
        "\n",
        "    # get everything but the test sample\n",
        "    train = df.drop(index=test.index)\n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "Qap0JMKVTumk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset, test_dataset = train_test_split(dataset)\n",
        "\n",
        "train_technical_analysis_dataset = TechnicalAnalysisDataset(train_dataset, DATA_CANDLE, transform=resize_transform)\n",
        "test_technical_analysis_dataset = TechnicalAnalysisDataset(test_dataset, DATA_CANDLE, transform=resize_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_technical_analysis_dataset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "      test_technical_analysis_dataset, batch_size=128, shuffle=False, num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "mm-lK_MoSuH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check\n",
        "img, label = train_technical_analysis_dataset.__getitem__(1)\n",
        "img = img.permute(1, 2, 0)\n",
        "print(img.shape)\n",
        "print(label)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "kVTEidsNOLEv",
        "outputId": "1c4a77e1-2f9b-49e7-fd6a-15c3e4e19eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 256, 4])\n",
            "2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training architecture"
      ],
      "metadata": {
        "id": "RiRBWJcjeiwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(epoch, model, train_loader, criterion, optimizer):\n",
        "  \"\"\"\n",
        "    epoch: int\n",
        "      Number of the current training epoch (starting from 0).\n",
        "    model: ResNet18\n",
        "      The model to train, which is an instance of the ResNet18 class.\n",
        "    train_loader: DataLoader\n",
        "      The training dataloader.\n",
        "    criterion: Module\n",
        "      A Module object that evaluates the crossentropy loss.\n",
        "    optimizer: Optimizer\n",
        "      An Optimizer object for the Adam optimizer.\n",
        "\n",
        "    Outputs: Returns average train_acc and train_loss for the current epoch.\n",
        "  \"\"\"\n",
        "  train_acc = 0.\n",
        "  train_loss = 0.\n",
        "  nb_data = 0 \n",
        "  model.train()\n",
        "  for inputs, labels in train_loader:\n",
        "      # Get input:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      # Zeros the parameter gradient\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # Foward + backward + optimize\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Get stats\n",
        "      train_loss += loss.item()\n",
        "      _, pred = torch.max(outputs.data, 1)\n",
        "      train_acc += (pred == labels).sum().item()\n",
        "      nb_data += labels.size(0)\n",
        "\n",
        "  train_loss = train_loss / len(train_loader)\n",
        "  train_acc = train_acc / nb_data\n",
        "\n",
        "  print(f\"Epoch: {epoch} | Train Acc: {train_acc:.6f} | Train Loss: {train_loss:.6f}\")\n",
        "  return train_acc, train_loss\n",
        "\n",
        "def valid_loop(epoch, model, val_loader, criterion):\n",
        "  \"\"\"\n",
        "    epoch: int\n",
        "      Number of the current epoch (starting from 0).\n",
        "    model: ResNet18\n",
        "      The model to train, which is an instance of the ResNet18 class.\n",
        "    val_loader: DataLoader\n",
        "      The validation dataloader.\n",
        "    criterion: Module\n",
        "      A Module object that evaluates the crossentropy loss.\n",
        "\n",
        "    Outputs: Returns average val_acc and val_loss for the current epoch.\n",
        "  \"\"\"\n",
        "  val_acc = 0.\n",
        "  val_loss = 0.\n",
        "  nb_data = 0\n",
        "\n",
        "  model.eval()\n",
        "  for inputs, labels in val_loader:\n",
        "      # Get input:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      \n",
        "      # Foward + backward + optimize\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # Get stats\n",
        "      val_loss += loss.item()\n",
        "      _, pred = torch.max(outputs.data, 1)\n",
        "      val_acc += (pred == labels).sum().item()\n",
        "      nb_data += labels.size(0)\n",
        "\n",
        "  val_loss = val_loss / len(val_loader)\n",
        "  val_acc = val_acc / nb_data\n",
        "\n",
        "  print(f\"Epoch: {epoch} | Val Acc: {val_acc:.6f}   | Val Loss: {val_loss:.6f}\")\n",
        "  return val_acc, val_loss"
      ],
      "metadata": {
        "id": "4oZXbuHdekvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models\n",
        "\n"
      ],
      "metadata": {
        "id": "YuBwOTFGchEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "-DlQCZrNfwZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.dropout import Dropout\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(4*256*256, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.Linear(512, 254),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.Linear(254, 3)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.flatten(start_dim=1)\n",
        "        out = self.model(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "LkD1kBpGcsxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "if __name__ == \"__main__\":\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "  train_accs, train_losses, val_accs, val_losses = [], [], [], []\n",
        "  n_epochs = 12\n",
        "\n",
        "  mlp = MLP().to(device)\n",
        "  nb_params = sum(p.numel() for p in mlp.parameters())\n",
        "  print(mlp)\n",
        "  print(f\"Number of parameter: {nb_params}\")\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(mlp.parameters())\n",
        "\n",
        "  tic = time.perf_counter()\n",
        "  for epoch in range(n_epochs):\n",
        "    # Training\n",
        "    train_acc, train_loss = train_loop(epoch, mlp, train_loader, criterion, optimizer)\n",
        "    train_accs.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validation\n",
        "    val_acc, val_loss = valid_loop(epoch, mlp, val_loader, criterion)\n",
        "    val_accs.append(val_acc)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "  toc = time.perf_counter()\n",
        "  print(f\"Time to train {toc - tic:0.4f} seconds\")"
      ],
      "metadata": {
        "id": "ZMeWCMs6dKOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resnet-18"
      ],
      "metadata": {
        "id": "GSDGC_SLcjZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, we can try with Resnet-18. This might be overkill, but why not, I won't trade any real money in the end"
      ],
      "metadata": {
        "id": "CVONtmeVJFty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  \"\"\"This class implements the Residual Block used in ResNet-18.\"\"\"\n",
        "\n",
        "  def __init__(self, in_channels, channels, conv_stride=1, activation_str=\"relu\", initialization=\"xavier_normal\"):\n",
        "    \"\"\"\n",
        "      Constructor for the ResidualBlock class.\n",
        "\n",
        "      in_channels: int\n",
        "        Number of channels in the input to the block.\n",
        "      channels: int\n",
        "        Number of output channels for the block, i.e., number of filters.\n",
        "      conv_stride: int, default 1\n",
        "        Stride of the first convolution layer and downsampling convolution (if required).\n",
        "      activation_str: string, default \"relu\"\n",
        "        Activation function to use.\n",
        "      initialization: string, default \"xavier_normal\"\n",
        "        Initialization for convolution layer weights.\n",
        "    \"\"\"\n",
        "    super(ResidualBlock, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.channels = channels\n",
        "    self.conv_stride = conv_stride\n",
        "    self.activation_str = activation_str\n",
        "    self.initialization = initialization\n",
        "\n",
        "    # Define these members by replacing `None` with the correct definitions\n",
        "    self.conv1 = nn.Conv2d(in_channels, channels, 3, stride=conv_stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(channels)\n",
        "    self.conv2 = nn.Conv2d(channels, channels, 3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    self.residual_connection = self.residual(in_channels, channels, conv_stride)\n",
        "\n",
        "    # Initialize weights for conv1 and conv2\n",
        "    if initialization == \"xavier_normal\":\n",
        "      nn.init.xavier_normal_(self.conv1.weight)\n",
        "      nn.init.xavier_normal_(self.conv2.weight)\n",
        "    elif initialization == \"xavier_uniform\": \n",
        "      nn.init.xavier_uniform_(self.conv1.weight)\n",
        "      nn.init.xavier_uniform_(self.conv2.weight)\n",
        "    elif initialization == \"kaiming_normal\": \n",
        "      nn.init.kaiming_normal_(self.conv1.weight)\n",
        "      nn.init.kaiming_normal_(self.conv2.weight)\n",
        "    else:\n",
        "      raise Exception(\"Invalid initialization\")\n",
        "\n",
        "  def activation(self, input):\n",
        "    \"\"\"\n",
        "      input: Tensor\n",
        "        Input on which the activation is applied.\n",
        "\n",
        "      Output: Result of activation function applied on input.\n",
        "        E.g. if self.activation_str is \"relu\", return relu(input).\n",
        "    \"\"\"\n",
        "    if self.activation_str == \"relu\":\n",
        "      return torch.relu(input)\n",
        "    elif self.activation_str == \"tanh\":\n",
        "      return torch.tanh(input)\n",
        "    else:\n",
        "      raise Exception(\"Invalid activation\")\n",
        "\n",
        "  def residual(self, in_channels, channels, conv_stride=1):\n",
        "    \"\"\"\n",
        "      in_channels: int\n",
        "        Number of input channels in the input to the block.\n",
        "      channels: int\n",
        "        Number of output channels for the block, i.e., number of filters.\n",
        "      conv_stride: int, default 1\n",
        "        Stride to use for downsampling 1x1 convolution.\n",
        "\n",
        "      Output: Returns an nn.Sequential object which computes the identity function of the input if stride is 1\n",
        "              and the number of input channels equals the number of output channels. Otherwise, it returns an\n",
        "              nn.Sequential object that downsamples its input using a 1x1-conv of the stride specified and\n",
        "              followed by a BatchNorm2d.\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    if conv_stride != 1 or in_channels != channels:\n",
        "      layers.append(nn.Conv2d(in_channels, channels, 1, stride=conv_stride, padding=0, bias=False))\n",
        "      layers.append(nn.BatchNorm2d(channels))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "      x: Tensor\n",
        "        Input to the block.\n",
        "\n",
        "      Outputs: Returns the output of the forward pass of the block.\n",
        "    \"\"\"\n",
        "    identity = x\n",
        "\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.activation(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    out += self.residual_connection(identity)\n",
        "    out = self.activation(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "zC5UvxiWHVf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can than create the model"
      ],
      "metadata": {
        "id": "8zps0LA5JaZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "  \"\"\"This class implements the ResNet-18 architecture from its components.\"\"\"\n",
        "\n",
        "  def __init__(self, activation_str=\"relu\", initialization=\"xavier_normal\"):\n",
        "    \"\"\"\n",
        "      Constructor for the ResNet18 class.\n",
        "\n",
        "      activation_str: string, default \"relu\"\n",
        "        Activation function to use.\n",
        "      initialization: string, default \"xavier_normal\"\n",
        "        Weight initialization to use.\n",
        "    \"\"\"\n",
        "    super(ResNet18, self).__init__()\n",
        "\n",
        "    self.n_classes = 10\n",
        "    self.activation_str = activation_str\n",
        "    self.initialization = initialization\n",
        "\n",
        "    self.conv1 = nn.Conv2d(4, 64, 3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._create_layer(64, 64) \n",
        "    self.layer2 = self._create_layer(64, 128, conv_stride=2)\n",
        "    self.layer3 = self._create_layer(128, 256, conv_stride=2)\n",
        "    self.layer4 = self._create_layer(256, 512, conv_stride=2)  \n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.linear = nn.Linear(512, 3)\n",
        "  \n",
        "  def activation(self, input):\n",
        "    \"\"\"\n",
        "      input: Tensor\n",
        "        Input on which the activation is applied.\n",
        "\n",
        "      Output: Result of activation function applied on input.\n",
        "        E.g. if self.activation_str is \"relu\", return relu(input).\n",
        "    \"\"\"\n",
        "    if self.activation_str == \"relu\":\n",
        "      return torch.relu(input)\n",
        "    elif self.activation_str == \"tanh\":\n",
        "      return torch.tanh(input)\n",
        "    else:\n",
        "      raise Exception(\"Invalid activation\")\n",
        "\n",
        "  def _create_layer(self, in_channels, channels, conv_stride=1):\n",
        "    \"\"\"\n",
        "      in_channels: int\n",
        "        Number of input channels present in the input to the layer.\n",
        "      out_channels: int\n",
        "        Number of output channels for the layer, i.e., the number of filters.\n",
        "      conv_stride: int, default 1\n",
        "        Stride of the first convolution layer in the block and the downsampling convolution (if required).\n",
        "\n",
        "      Outputs: Returns an nn.Sequential object giving a \"layer\" of the ResNet, consisting of 2 blocks each.\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        ResidualBlock(in_channels, channels, conv_stride=conv_stride, activation_str=self.activation_str, initialization=self.initialization),\n",
        "        ResidualBlock(channels, channels, conv_stride=1, activation_str=self.activation_str, initialization=self.initialization)\n",
        "    )\n",
        "\n",
        "  def get_first_conv_layer_filters(self):\n",
        "    \"\"\"\n",
        "      Outputs: Returns the filters in the first convolution layer.\n",
        "    \"\"\"\n",
        "    return self.conv1.weight.clone().cpu().detach().numpy()\n",
        "\n",
        "  def get_last_conv_layer_filters(self):\n",
        "    \"\"\"\n",
        "      Outputs: Returns the filters in the last convolution layer.\n",
        "    \"\"\"\n",
        "    return list(self.layer4.modules())[1].conv2.weight.clone().cpu().detach().numpy()\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "      x: Tensor\n",
        "        Input to the network.\n",
        "\n",
        "      Outputs: Returns the output of the forward pass of the network.\n",
        "    \"\"\"\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.activation(out)\n",
        "\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    \n",
        "    out = self.avgpool(out)\n",
        "    out = torch.flatten(out, 1)\n",
        "    out = self.linear(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "PQEYJqEnIoeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter we will use\n",
        "activation_str = \"relu\"\n",
        "initialization = \"xavier_normal\""
      ],
      "metadata": {
        "id": "p9T2Rjk8Irxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "if __name__ == \"__main__\":\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "  train_accs, train_losses, val_accs, val_losses = [], [], [], []\n",
        "  n_epochs = 25\n",
        "\n",
        "  model = ResNet18(\n",
        "    activation_str=activation_str,\n",
        "    initialization=initialization\n",
        "  ).to(device)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "  for epoch in range(n_epochs):\n",
        "    # Training\n",
        "    train_acc, train_loss = train_loop(epoch, model, train_loader, criterion, optimizer)\n",
        "    train_accs.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validation\n",
        "    val_acc, val_loss = valid_loop(epoch, model, val_loader, criterion)\n",
        "    val_accs.append(val_acc)\n",
        "    val_losses.append(val_loss)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjOLei3SJn6v",
        "outputId": "47923d20-f493-4a02-ba29-92ea6320c9ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Acc: 0.375000 | Train Loss: 2.266934\n",
            "Epoch: 0 | Val Acc: 0.500000   | Val Loss: 2.936660\n",
            "Epoch: 1 | Train Acc: 0.458333 | Train Loss: 1.434008\n",
            "Epoch: 1 | Val Acc: 0.500000   | Val Loss: 3.821058\n",
            "Epoch: 2 | Train Acc: 0.583333 | Train Loss: 1.031421\n",
            "Epoch: 2 | Val Acc: 0.500000   | Val Loss: 1.956096\n",
            "Epoch: 3 | Train Acc: 0.583333 | Train Loss: 0.872833\n",
            "Epoch: 3 | Val Acc: 0.166667   | Val Loss: 1.847805\n",
            "Epoch: 4 | Train Acc: 0.666667 | Train Loss: 0.705132\n",
            "Epoch: 4 | Val Acc: 0.333333   | Val Loss: 1.559400\n",
            "Epoch: 5 | Train Acc: 0.791667 | Train Loss: 0.572029\n",
            "Epoch: 5 | Val Acc: 0.333333   | Val Loss: 1.330200\n",
            "Epoch: 6 | Train Acc: 0.833333 | Train Loss: 0.446711\n",
            "Epoch: 6 | Val Acc: 0.500000   | Val Loss: 1.427253\n",
            "Epoch: 7 | Train Acc: 1.000000 | Train Loss: 0.332901\n",
            "Epoch: 7 | Val Acc: 0.500000   | Val Loss: 1.809139\n",
            "Epoch: 8 | Train Acc: 1.000000 | Train Loss: 0.233001\n",
            "Epoch: 8 | Val Acc: 0.500000   | Val Loss: 1.962750\n",
            "Epoch: 9 | Train Acc: 1.000000 | Train Loss: 0.184717\n",
            "Epoch: 9 | Val Acc: 0.500000   | Val Loss: 1.884438\n",
            "Epoch: 10 | Train Acc: 1.000000 | Train Loss: 0.132077\n",
            "Epoch: 10 | Val Acc: 0.500000   | Val Loss: 1.789932\n",
            "Epoch: 11 | Train Acc: 1.000000 | Train Loss: 0.093176\n",
            "Epoch: 11 | Val Acc: 0.500000   | Val Loss: 1.633231\n",
            "Epoch: 12 | Train Acc: 1.000000 | Train Loss: 0.069862\n",
            "Epoch: 12 | Val Acc: 0.500000   | Val Loss: 1.485668\n",
            "Epoch: 13 | Train Acc: 1.000000 | Train Loss: 0.045308\n",
            "Epoch: 13 | Val Acc: 0.500000   | Val Loss: 1.350421\n",
            "Epoch: 14 | Train Acc: 1.000000 | Train Loss: 0.034730\n",
            "Epoch: 14 | Val Acc: 0.500000   | Val Loss: 1.314010\n",
            "Epoch: 15 | Train Acc: 1.000000 | Train Loss: 0.020887\n",
            "Epoch: 15 | Val Acc: 0.500000   | Val Loss: 1.480968\n",
            "Epoch: 16 | Train Acc: 1.000000 | Train Loss: 0.017822\n",
            "Epoch: 16 | Val Acc: 0.500000   | Val Loss: 1.802689\n",
            "Epoch: 17 | Train Acc: 1.000000 | Train Loss: 0.012764\n",
            "Epoch: 17 | Val Acc: 0.500000   | Val Loss: 2.115968\n",
            "Epoch: 18 | Train Acc: 1.000000 | Train Loss: 0.010071\n",
            "Epoch: 18 | Val Acc: 0.500000   | Val Loss: 2.173847\n",
            "Epoch: 19 | Train Acc: 1.000000 | Train Loss: 0.008766\n",
            "Epoch: 19 | Val Acc: 0.500000   | Val Loss: 1.950229\n",
            "Epoch: 20 | Train Acc: 1.000000 | Train Loss: 0.006850\n",
            "Epoch: 20 | Val Acc: 0.500000   | Val Loss: 1.590899\n",
            "Epoch: 21 | Train Acc: 1.000000 | Train Loss: 0.005979\n",
            "Epoch: 21 | Val Acc: 0.500000   | Val Loss: 1.345067\n",
            "Epoch: 22 | Train Acc: 1.000000 | Train Loss: 0.005253\n",
            "Epoch: 22 | Val Acc: 0.333333   | Val Loss: 1.252151\n",
            "Epoch: 23 | Train Acc: 1.000000 | Train Loss: 0.004425\n",
            "Epoch: 23 | Val Acc: 0.333333   | Val Loss: 1.206566\n",
            "Epoch: 24 | Train Acc: 1.000000 | Train Loss: 0.003570\n",
            "Epoch: 24 | Val Acc: 0.333333   | Val Loss: 1.140205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    torch.save(model, \"resnet18\")"
      ],
      "metadata": {
        "id": "JkE0SOY3JxpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    model = torch.load(\"resnet18\")"
      ],
      "metadata": {
        "id": "L9LO8nisJzy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see if the model learn something"
      ],
      "metadata": {
        "id": "CBEIn2-pJ2Cz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QqC_niU2J60I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can finaly look how the model extract this information by looking at the learned filter"
      ],
      "metadata": {
        "id": "ryP-HL08J8pC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First layer"
      ],
      "metadata": {
        "id": "DZAgV1PjKaJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_filter(filters, n_filter_to_display=6):\n",
        "    # Normalize \n",
        "    f_min, f_max = filters.max(), filters.min()\n",
        "    filters = (filters - f_min) / (f_max - f_min)\n",
        "\n",
        "    i_idx = 1\n",
        "    for f_idx in range(n_filter_to_display):\n",
        "        filter = filters[f_idx, :, :, :]\n",
        "        for p_idx in range(3):\n",
        "            ax = plt.subplot(n_filter_to_display, 3, i_idx)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            # Plot\n",
        "            plt.imshow(filter[p_idx,:,:], cmap='gray')\n",
        "            i_idx += 1\n",
        "    plt.show()\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    print(\"First layer filters\")\n",
        "    first_filters = model.get_first_conv_layer_filters()\n",
        "    print_filter(first_filters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "mJ3Xegc2KfN0",
        "outputId": "548e59d7-e609-4df9-9456-c36f2a280b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First layer filters\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 18 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Last layer filters\")\n",
        "    last_filters = model.get_last_conv_layer_filters()\n",
        "    print_filter(last_filters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "RYjeVJRkKg1D",
        "outputId": "20800a17-ec17-44af-c733-6bd4e6f8c704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last layer filters\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 18 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let see what the graph look like with those filter"
      ],
      "metadata": {
        "id": "WHEW5UQdKhw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Fin output size\n",
        "    img, label = train_technical_analysis_dataset.__getitem__(0)\n",
        "    # vis_image = img.permute(1, 2, 0)\n",
        "    vis_image = img\n",
        "    channel, dim_x_img, dim_y_img = vis_image.shape\n",
        "    dim_out = (dim_x_img-3)//1 + 1\n",
        "\n",
        "    output = np.zeros((64, dim_out, dim_out))\n",
        "\n",
        "    for filter_idx in range(first_filters.shape[0]):\n",
        "        filter = first_filters[filter_idx]\n",
        "\n",
        "        for channel_i in range(filter.shape[0]):\n",
        "            # Apply kernel\n",
        "            kernel = filter[channel_i]\n",
        "            img = vis_image[channel_i].numpy()\n",
        "            for i in range(0, dim_out):\n",
        "                for j in range(0, dim_out):\n",
        "                    # Select part of the img\n",
        "                    img_patch = img[i:i+3, j:j+3]\n",
        "                    # Apply kernel\n",
        "                    kernel_output = np.multiply(img_patch, kernel)\n",
        "                    kernel_output = np.sum(kernel_output)\n",
        "                    # Save output\n",
        "                    output[filter_idx, i, j] = kernel_output\n",
        "\n",
        "    from matplotlib.pyplot import figure\n",
        "    figure(figsize=(10,10))\n",
        "\n",
        "    ax = [plt.subplot(8,8,i+1) for i in range(64)]\n",
        "\n",
        "    for i, a in enumerate(ax):\n",
        "        a.set_xticks([])\n",
        "        a.set_yticks([])\n",
        "\n",
        "        a.imshow(output[i,:,:], cmap='gray')\n",
        "\n",
        "    plt.subplots_adjust(wspace=0., hspace=0.1)\n"
      ],
      "metadata": {
        "id": "KsR40u58KWYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last layer"
      ],
      "metadata": {
        "id": "9fQXFdM0KYvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    model_extract_last_features = create_feature_extractor(model, {\"layer4\": \"layer4\"})\n",
        "    out = model_extract_last_features(vis_image.to(device))\n",
        "    out['layer4'].shape\n",
        "\n",
        "    figure(figsize=(10,10))\n",
        "\n",
        "    ax = [plt.subplot(8,8,i+1) for i in range(64)]\n",
        "\n",
        "    for i, a in enumerate(ax):\n",
        "        a.set_xticks([])\n",
        "        a.set_yticks([])\n",
        "\n",
        "        image = out['layer4'].cpu().detach().numpy()[0, i,:,:]\n",
        "        a.imshow(image, cmap='gray')\n",
        "\n",
        "    plt.subplots_adjust(wspace=0., hspace=0.1)"
      ],
      "metadata": {
        "id": "Ny6RkagGKYR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ViT"
      ],
      "metadata": {
        "id": "Alc2VeOhlRz-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xu9sqc08lTji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's trade some stock and loose money, but in style hehe"
      ],
      "metadata": {
        "id": "HGfi9001Krot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "zK2F0__TKyZ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}