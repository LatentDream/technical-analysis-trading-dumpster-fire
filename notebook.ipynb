{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsZfH9lbJcWVi5jfo18sLd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guthi1/technical-analysis-trading-dumpster-fire/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PolyFinances article"
      ],
      "metadata": {
        "id": "TGZQ-Jkye0BQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO: Explain de situation"
      ],
      "metadata": {
        "id": "F3iLBE-1e3Ns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF5x7nDEdY9x"
      },
      "outputs": [],
      "source": [
        "# Install required librairy\n",
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import numpy as np\n",
        "import yfinance as yf"
      ],
      "metadata": {
        "id": "zD_g1JuKfx5z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG = True\n",
        "DATA_DIR = \"data/\"\n",
        "DATA_CANDLE = \"data/candle/\"\n",
        "DATA_NORMAL = \"data/normal/\"\n",
        "!mkdir data\n",
        "!mkdir data/candle\n",
        "!mkdir data/normal\n",
        "PRICE_INTERVAL = 2 # In minute, Must be in: 1m,2m,5m,15m,30m,60m,90m\n",
        "WINDOWS_INTERVAL = 60 # In minute, must be > than PRICE_INTERVAL\n",
        "assert WINDOWS_INTERVAL > PRICE_INTERVAL, \"window for analysis must be greater than the price interval\"\n",
        "\n",
        "HOLD = 0\n",
        "BUY = 1\n",
        "SELL = 2"
      ],
      "metadata": {
        "id": "wuce5Hq4ojJ-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataset"
      ],
      "metadata": {
        "id": "1KK0lczQoX2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data\n",
        "data = yf.download(  # or pdr.get_data_yahoo(...\n",
        "        # tickers list or string as well\n",
        "        tickers = \"SPY AAPL MSFT TSLA GE F AMZN AQN TD\",\n",
        "        # use \"period\" instead of start/end\n",
        "        # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
        "        # (optional, default is '1mo')\n",
        "        period = \"5d\",\n",
        "        # fetch data by interval (including intraday if period < 60 days)\n",
        "        # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
        "        interval = f\"{PRICE_INTERVAL}m\",\n",
        "        # group by ticker (to access via data['SPY'])\n",
        "        # (optional, default is 'column')\n",
        "        group_by = 'ticker',\n",
        "        # attempt repair of missing data or currency mixups e.g. $/cents\n",
        "        repair = True,\n",
        "        # use threads for mass downloading\n",
        "        threads = True\n",
        "    )\n",
        "\n",
        "print(f\"Number of row: {len(data)}\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "calvm5Tdd9Ll",
        "outputId": "38579174-f95a-43cd-8b08-53c4e1dab1ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  9 of 9 completed\n",
            "Number of row: 976\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       AQN                                                F  \\\n",
              "                      Open    High     Low  Close Adj Close  Volume    Open   \n",
              "Datetime                                                                      \n",
              "2023-01-09 09:30:00  7.270  7.3200  7.2700  7.275     7.275  175230  12.740   \n",
              "2023-01-09 09:32:00  7.275  7.2750  7.2307  7.240     7.240   27923  12.720   \n",
              "2023-01-09 09:34:00  7.240  7.2422  7.2000  7.215     7.215   55662  12.650   \n",
              "2023-01-09 09:36:00  7.220  7.2400  7.2100  7.225     7.225  110361  12.690   \n",
              "2023-01-09 09:38:00  7.230  7.2400  7.2100  7.230     7.230   69507  12.625   \n",
              "\n",
              "                                            ...       AMZN             \\\n",
              "                      High    Low    Close  ...        Low      Close   \n",
              "Datetime                                    ...                         \n",
              "2023-01-09 09:30:00  12.76  12.67  12.7101  ...  87.459999  88.410004   \n",
              "2023-01-09 09:32:00  12.73  12.65  12.6515  ...  88.150101  88.500000   \n",
              "2023-01-09 09:34:00  12.70  12.64  12.6850  ...  88.290001  88.470001   \n",
              "2023-01-09 09:36:00  12.70  12.62  12.6200  ...  87.909897  88.157303   \n",
              "2023-01-09 09:38:00  12.66  12.58  12.5950  ...  88.120003  88.394997   \n",
              "\n",
              "                                                SPY                          \\\n",
              "                     Adj Close   Volume        Open        High         Low   \n",
              "Datetime                                                                      \n",
              "2023-01-09 09:30:00  88.410004  3916487  390.369995  390.450012  389.839996   \n",
              "2023-01-09 09:32:00  88.500000  1074282  390.440002  390.839996  390.130005   \n",
              "2023-01-09 09:34:00  88.470001   712346  390.160004  390.309998  389.709991   \n",
              "2023-01-09 09:36:00  88.157303   985453  389.829987  389.959991  389.420013   \n",
              "2023-01-09 09:38:00  88.394997   708215  389.630005  389.920105  389.350006   \n",
              "\n",
              "                                                      \n",
              "                          Close   Adj Close   Volume  \n",
              "Datetime                                              \n",
              "2023-01-09 09:30:00  390.410004  390.410004  2402676  \n",
              "2023-01-09 09:32:00  390.170013  390.170013   487845  \n",
              "2023-01-09 09:34:00  389.825012  389.825012   501256  \n",
              "2023-01-09 09:36:00  389.639709  389.639709   451951  \n",
              "2023-01-09 09:38:00  389.880005  389.880005   367161  \n",
              "\n",
              "[5 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-719e16a3-29d4-42d3-acf2-006cb0236f15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">AQN</th>\n",
              "      <th colspan=\"4\" halign=\"left\">F</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"4\" halign=\"left\">AMZN</th>\n",
              "      <th colspan=\"6\" halign=\"left\">SPY</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-09 09:30:00</th>\n",
              "      <td>7.270</td>\n",
              "      <td>7.3200</td>\n",
              "      <td>7.2700</td>\n",
              "      <td>7.275</td>\n",
              "      <td>7.275</td>\n",
              "      <td>175230</td>\n",
              "      <td>12.740</td>\n",
              "      <td>12.76</td>\n",
              "      <td>12.67</td>\n",
              "      <td>12.7101</td>\n",
              "      <td>...</td>\n",
              "      <td>87.459999</td>\n",
              "      <td>88.410004</td>\n",
              "      <td>88.410004</td>\n",
              "      <td>3916487</td>\n",
              "      <td>390.369995</td>\n",
              "      <td>390.450012</td>\n",
              "      <td>389.839996</td>\n",
              "      <td>390.410004</td>\n",
              "      <td>390.410004</td>\n",
              "      <td>2402676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09 09:32:00</th>\n",
              "      <td>7.275</td>\n",
              "      <td>7.2750</td>\n",
              "      <td>7.2307</td>\n",
              "      <td>7.240</td>\n",
              "      <td>7.240</td>\n",
              "      <td>27923</td>\n",
              "      <td>12.720</td>\n",
              "      <td>12.73</td>\n",
              "      <td>12.65</td>\n",
              "      <td>12.6515</td>\n",
              "      <td>...</td>\n",
              "      <td>88.150101</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>1074282</td>\n",
              "      <td>390.440002</td>\n",
              "      <td>390.839996</td>\n",
              "      <td>390.130005</td>\n",
              "      <td>390.170013</td>\n",
              "      <td>390.170013</td>\n",
              "      <td>487845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09 09:34:00</th>\n",
              "      <td>7.240</td>\n",
              "      <td>7.2422</td>\n",
              "      <td>7.2000</td>\n",
              "      <td>7.215</td>\n",
              "      <td>7.215</td>\n",
              "      <td>55662</td>\n",
              "      <td>12.650</td>\n",
              "      <td>12.70</td>\n",
              "      <td>12.64</td>\n",
              "      <td>12.6850</td>\n",
              "      <td>...</td>\n",
              "      <td>88.290001</td>\n",
              "      <td>88.470001</td>\n",
              "      <td>88.470001</td>\n",
              "      <td>712346</td>\n",
              "      <td>390.160004</td>\n",
              "      <td>390.309998</td>\n",
              "      <td>389.709991</td>\n",
              "      <td>389.825012</td>\n",
              "      <td>389.825012</td>\n",
              "      <td>501256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09 09:36:00</th>\n",
              "      <td>7.220</td>\n",
              "      <td>7.2400</td>\n",
              "      <td>7.2100</td>\n",
              "      <td>7.225</td>\n",
              "      <td>7.225</td>\n",
              "      <td>110361</td>\n",
              "      <td>12.690</td>\n",
              "      <td>12.70</td>\n",
              "      <td>12.62</td>\n",
              "      <td>12.6200</td>\n",
              "      <td>...</td>\n",
              "      <td>87.909897</td>\n",
              "      <td>88.157303</td>\n",
              "      <td>88.157303</td>\n",
              "      <td>985453</td>\n",
              "      <td>389.829987</td>\n",
              "      <td>389.959991</td>\n",
              "      <td>389.420013</td>\n",
              "      <td>389.639709</td>\n",
              "      <td>389.639709</td>\n",
              "      <td>451951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09 09:38:00</th>\n",
              "      <td>7.230</td>\n",
              "      <td>7.2400</td>\n",
              "      <td>7.2100</td>\n",
              "      <td>7.230</td>\n",
              "      <td>7.230</td>\n",
              "      <td>69507</td>\n",
              "      <td>12.625</td>\n",
              "      <td>12.66</td>\n",
              "      <td>12.58</td>\n",
              "      <td>12.5950</td>\n",
              "      <td>...</td>\n",
              "      <td>88.120003</td>\n",
              "      <td>88.394997</td>\n",
              "      <td>88.394997</td>\n",
              "      <td>708215</td>\n",
              "      <td>389.630005</td>\n",
              "      <td>389.920105</td>\n",
              "      <td>389.350006</td>\n",
              "      <td>389.880005</td>\n",
              "      <td>389.880005</td>\n",
              "      <td>367161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-719e16a3-29d4-42d3-acf2-006cb0236f15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-719e16a3-29d4-42d3-acf2-006cb0236f15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-719e16a3-29d4-42d3-acf2-006cb0236f15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build dataset"
      ],
      "metadata": {
        "id": "40KdeKTSD948"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_number = 0\n",
        "# Dataframe to save the value we need\n",
        "dataset={\"candle_path\": [], \"normal_path\": [], \"action\": [], \"info\": [], \"filename\": []}"
      ],
      "metadata": {
        "id": "TmFepAAuGoKt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try it for ford first\n",
        "ticker = \"F\"\n",
        "ticker_data = data[ticker]\n",
        "ticker_data.dropna() # Sanity check\n",
        "ticker_data[\"datetime\"] = ticker_data.index\n",
        "\n",
        "# Find Dataset range\n",
        "day = ticker_data['datetime'].min()\n",
        "last_end = ticker_data['datetime'].max()\n",
        "if DEBUG: print(f\"From {day} to {last_end}\")\n",
        "\n",
        "plt.close()\n",
        "\n",
        "while day <= last_end:\n",
        "    if DEBUG: print(f\"{day}\")\n",
        "\n",
        "    start_window = day\n",
        "    end_window = start_window + datetime.timedelta(minutes=WINDOWS_INTERVAL)\n",
        "    end_of_day = day + datetime.timedelta(hours=6.5)\n",
        "\n",
        "    while start_window < end_of_day - datetime.timedelta(minutes=WINDOWS_INTERVAL):\n",
        "        if DEBUG: print(f\"    {start_window}\")\n",
        "\n",
        "        # Create a mask for the desired window\n",
        "        mask = (ticker_data['datetime'] > start_window) & (ticker_data['datetime'] <= end_window)\n",
        "        window_data = ticker_data.loc[mask]\n",
        "        \"\"\" TODO: This could be change to something smarter \"\"\"\n",
        "        mean_close = window_data.Close.mean()\n",
        "\n",
        "        # \"up\" dataframe will store the stock_prices when the closing stock \n",
        "        # price is greater than or equal to the opening stock prices\n",
        "        up = window_data[window_data.Close >= window_data.Open]\n",
        "        col1 = 'red'\n",
        "\n",
        "        # \"down\" dataframe will store the stock_prices when the closing stock \n",
        "        # price is lesser than the opening stock prices\n",
        "        down = window_data[window_data.Close < window_data.Open]\n",
        "        col2 = 'blue'\n",
        "\n",
        "        # Setting width of candlestick elements\n",
        "        width = .0005\n",
        "        width2 = .00008\n",
        "\n",
        "        # Plotting up prices of the stock\n",
        "        plt.bar(up.datetime, up.Close-up.Open, width, bottom=up.Open, color=col1)\n",
        "        plt.bar(up.datetime, up.High-up.Close, width2, bottom=up.Close, color=col1)\n",
        "        plt.bar(up.datetime, up.Low-up.Open, width2, bottom=up.Open, color=col1)\n",
        "\n",
        "        # Plotting down prices of the stock\n",
        "        plt.bar(down.datetime, down.Close-down.Open, width, bottom=down.Open, color=col2)\n",
        "        plt.bar(down.datetime, down.High-down.Open, width2, bottom=down.Open, color=col2)\n",
        "        plt.bar(down.datetime, down.Low-down.Close, width2, bottom=down.Close, color=col2)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Saving the candle plot\n",
        "        plt_name = f\"{plot_number}.png\"\n",
        "        plt.savefig(f\"{DATA_CANDLE}{plt_name}\", format=\"png\")\n",
        "        plt.close()    \n",
        "        dataset[\"filename\"].append(plt_name)\n",
        "        dataset[\"candle_path\"].append(DATA_CANDLE)\n",
        "\n",
        "        # Plotting the time series of given dataframe\n",
        "        plt.plot(window_data[\"datetime\"], window_data[\"Adj Close\"])\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Saving the normal plot\n",
        "        plt_name = f\"{DATA_NORMAL}{plot_number}.png\"\n",
        "        plt.savefig(plt_name, format=\"png\")\n",
        "        plt.close()    \n",
        "        dataset[\"normal_path\"].append(DATA_CANDLE)\n",
        "        \n",
        "        # Update var\n",
        "        plot_number += 1\n",
        "        start_window = end_window\n",
        "        end_window = start_window + datetime.timedelta(minutes=WINDOWS_INTERVAL)\n",
        "\n",
        "        # Check if it's a hold, buy and sold\n",
        "        \"\"\" TODO: This could be change to something smarter \"\"\"\n",
        "        mask = (ticker_data['datetime'] > start_window) & (ticker_data['datetime'] <= end_window)\n",
        "        window_data = ticker_data.loc[mask]\n",
        "        mean_close_next_interval = window_data.Close.mean()\n",
        "\n",
        "        diff = mean_close_next_interval / mean_close\n",
        "        if diff > 1.002:\n",
        "            dataset[\"action\"].append(BUY)\n",
        "        elif diff < 0.998:\n",
        "            dataset[\"action\"].append(SELL)\n",
        "        else:\n",
        "            dataset[\"action\"].append(HOLD)\n",
        "\n",
        "        # For debugging later\n",
        "        dataset[\"info\"].append(f\"{ticker}: {start_window}\")\n",
        "\n",
        "    day += datetime.timedelta(days=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy7tT02qyNNq",
        "outputId": "06bf2bcd-776a-4de1-f686-b763b3fa466a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-c69a98fb9b34>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ticker_data[\"datetime\"] = ticker_data.index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From 2023-01-09 09:30:00 to 2023-01-13 16:00:00\n",
            "2023-01-09 09:30:00\n",
            "    2023-01-09 09:30:00\n",
            "    2023-01-09 10:30:00\n",
            "    2023-01-09 11:30:00\n",
            "    2023-01-09 12:30:00\n",
            "    2023-01-09 13:30:00\n",
            "    2023-01-09 14:30:00\n",
            "2023-01-10 09:30:00\n",
            "    2023-01-10 09:30:00\n",
            "    2023-01-10 10:30:00\n",
            "    2023-01-10 11:30:00\n",
            "    2023-01-10 12:30:00\n",
            "    2023-01-10 13:30:00\n",
            "    2023-01-10 14:30:00\n",
            "2023-01-11 09:30:00\n",
            "    2023-01-11 09:30:00\n",
            "    2023-01-11 10:30:00\n",
            "    2023-01-11 11:30:00\n",
            "    2023-01-11 12:30:00\n",
            "    2023-01-11 13:30:00\n",
            "    2023-01-11 14:30:00\n",
            "2023-01-12 09:30:00\n",
            "    2023-01-12 09:30:00\n",
            "    2023-01-12 10:30:00\n",
            "    2023-01-12 11:30:00\n",
            "    2023-01-12 12:30:00\n",
            "    2023-01-12 13:30:00\n",
            "    2023-01-12 14:30:00\n",
            "2023-01-13 09:30:00\n",
            "    2023-01-13 09:30:00\n",
            "    2023-01-13 10:30:00\n",
            "    2023-01-13 11:30:00\n",
            "    2023-01-13 12:30:00\n",
            "    2023-01-13 13:30:00\n",
            "    2023-01-13 14:30:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.DataFrame(data=dataset)\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pLxH4U3nFKii",
        "outputId": "c8775397-f417-43d0-9287-c7208e655530"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    candle_path   normal_path  action                    info filename\n",
              "0  data/candle/  data/candle/       1  F: 2023-01-09 10:30:00    0.png\n",
              "1  data/candle/  data/candle/       1  F: 2023-01-09 11:30:00    1.png\n",
              "2  data/candle/  data/candle/       2  F: 2023-01-09 12:30:00    2.png\n",
              "3  data/candle/  data/candle/       0  F: 2023-01-09 13:30:00    3.png\n",
              "4  data/candle/  data/candle/       2  F: 2023-01-09 14:30:00    4.png"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91ebeee8-2515-4e5e-a96e-3aefc1015f28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>candle_path</th>\n",
              "      <th>normal_path</th>\n",
              "      <th>action</th>\n",
              "      <th>info</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/candle/</td>\n",
              "      <td>data/candle/</td>\n",
              "      <td>1</td>\n",
              "      <td>F: 2023-01-09 10:30:00</td>\n",
              "      <td>0.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/candle/</td>\n",
              "      <td>data/candle/</td>\n",
              "      <td>1</td>\n",
              "      <td>F: 2023-01-09 11:30:00</td>\n",
              "      <td>1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/candle/</td>\n",
              "      <td>data/candle/</td>\n",
              "      <td>2</td>\n",
              "      <td>F: 2023-01-09 12:30:00</td>\n",
              "      <td>2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/candle/</td>\n",
              "      <td>data/candle/</td>\n",
              "      <td>0</td>\n",
              "      <td>F: 2023-01-09 13:30:00</td>\n",
              "      <td>3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/candle/</td>\n",
              "      <td>data/candle/</td>\n",
              "      <td>2</td>\n",
              "      <td>F: 2023-01-09 14:30:00</td>\n",
              "      <td>4.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91ebeee8-2515-4e5e-a96e-3aefc1015f28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91ebeee8-2515-4e5e-a96e-3aefc1015f28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91ebeee8-2515-4e5e-a96e-3aefc1015f28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trading model\n",
        "\n",
        "We will need torch"
      ],
      "metadata": {
        "id": "PCYx7Z2UHTED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.io import read_image\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Fix random seed\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "k3eRQkNiIeqc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a data loader for the dataset we created"
      ],
      "metadata": {
        "id": "GOlnoVvLI4Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TechnicalAnalysisDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, chart_dir, transform=None):\n",
        "        self.df = data\n",
        "        self.img_dir = chart_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.df.iloc[idx][\"filename\"])\n",
        "        image = read_image(img_path)\n",
        "        image = image / 255\n",
        "        label = self.df.iloc[idx][\"action\"]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "fa2N7CRBI6J2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformation needed for the ResnetModel\n",
        "resize_transform = transforms.Resize(size=(256, 256))\n",
        "# Create the dataset\n",
        "technical_analysis_dataset = TechnicalAnalysisDataset(dataset, DATA_CANDLE, transform=resize_transform)"
      ],
      "metadata": {
        "id": "bNjILDb7N3wI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check\n",
        "img, label = technical_analysis_dataset.__getitem__(0)\n",
        "img = img.permute(1, 2, 0)\n",
        "print(img.shape)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "kVTEidsNOLEv",
        "outputId": "53ded42b-d64d-404a-daa8-c587b1358672"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 256, 4])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our dataset, we will need to split it in a training and validation set and we will need a data loader to be able to have minibatch."
      ],
      "metadata": {
        "id": "g_JWp5T3Sfdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(df, frac=0.2):\n",
        "    \n",
        "    # get random sample \n",
        "    test = df.sample(frac=frac, axis=0)\n",
        "\n",
        "    # get everything but the test sample\n",
        "    train = df.drop(index=test.index)\n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "Qap0JMKVTumk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset, test_dataset = train_test_split(dataset)\n",
        "\n",
        "train_technical_analysis_dataset = TechnicalAnalysisDataset(train_dataset, DATA_CANDLE, transform=resize_transform)\n",
        "test_technical_analysis_dataset = TechnicalAnalysisDataset(test_dataset, DATA_CANDLE, transform=resize_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_technical_analysis_dataset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "      test_technical_analysis_dataset, batch_size=128, shuffle=False, num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "mm-lK_MoSuH_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can start with Resnet-18. This might be overkill, but why not, I won't trade any real money, that for suuuuuuuuuuuurrrrrreeeeeee."
      ],
      "metadata": {
        "id": "CVONtmeVJFty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  \"\"\"This class implements the Residual Block used in ResNet-18.\"\"\"\n",
        "\n",
        "  def __init__(self, in_channels, channels, conv_stride=1, activation_str=\"relu\", initialization=\"xavier_normal\"):\n",
        "    \"\"\"\n",
        "      Constructor for the ResidualBlock class.\n",
        "\n",
        "      in_channels: int\n",
        "        Number of channels in the input to the block.\n",
        "      channels: int\n",
        "        Number of output channels for the block, i.e., number of filters.\n",
        "      conv_stride: int, default 1\n",
        "        Stride of the first convolution layer and downsampling convolution (if required).\n",
        "      activation_str: string, default \"relu\"\n",
        "        Activation function to use.\n",
        "      initialization: string, default \"xavier_normal\"\n",
        "        Initialization for convolution layer weights.\n",
        "    \"\"\"\n",
        "    super(ResidualBlock, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.channels = channels\n",
        "    self.conv_stride = conv_stride\n",
        "    self.activation_str = activation_str\n",
        "    self.initialization = initialization\n",
        "\n",
        "    # Define these members by replacing `None` with the correct definitions\n",
        "    self.conv1 = nn.Conv2d(in_channels, channels, 3, stride=conv_stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(channels)\n",
        "    self.conv2 = nn.Conv2d(channels, channels, 3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    self.residual_connection = self.residual(in_channels, channels, conv_stride)\n",
        "\n",
        "    # Initialize weights for conv1 and conv2\n",
        "    if initialization == \"xavier_normal\":\n",
        "      nn.init.xavier_normal_(self.conv1.weight)\n",
        "      nn.init.xavier_normal_(self.conv2.weight)\n",
        "    elif initialization == \"xavier_uniform\": \n",
        "      nn.init.xavier_uniform_(self.conv1.weight)\n",
        "      nn.init.xavier_uniform_(self.conv2.weight)\n",
        "    elif initialization == \"kaiming_normal\": \n",
        "      nn.init.kaiming_normal_(self.conv1.weight)\n",
        "      nn.init.kaiming_normal_(self.conv2.weight)\n",
        "    else:\n",
        "      raise Exception(\"Invalid initialization\")\n",
        "\n",
        "  def activation(self, input):\n",
        "    \"\"\"\n",
        "      input: Tensor\n",
        "        Input on which the activation is applied.\n",
        "\n",
        "      Output: Result of activation function applied on input.\n",
        "        E.g. if self.activation_str is \"relu\", return relu(input).\n",
        "    \"\"\"\n",
        "    if self.activation_str == \"relu\":\n",
        "      return torch.relu(input)\n",
        "    elif self.activation_str == \"tanh\":\n",
        "      return torch.tanh(input)\n",
        "    else:\n",
        "      raise Exception(\"Invalid activation\")\n",
        "\n",
        "  def residual(self, in_channels, channels, conv_stride=1):\n",
        "    \"\"\"\n",
        "      in_channels: int\n",
        "        Number of input channels in the input to the block.\n",
        "      channels: int\n",
        "        Number of output channels for the block, i.e., number of filters.\n",
        "      conv_stride: int, default 1\n",
        "        Stride to use for downsampling 1x1 convolution.\n",
        "\n",
        "      Output: Returns an nn.Sequential object which computes the identity function of the input if stride is 1\n",
        "              and the number of input channels equals the number of output channels. Otherwise, it returns an\n",
        "              nn.Sequential object that downsamples its input using a 1x1-conv of the stride specified and\n",
        "              followed by a BatchNorm2d.\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    if conv_stride != 1 or in_channels != channels:\n",
        "      layers.append(nn.Conv2d(in_channels, channels, 1, stride=conv_stride, padding=0, bias=False))\n",
        "      layers.append(nn.BatchNorm2d(channels))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "      x: Tensor\n",
        "        Input to the block.\n",
        "\n",
        "      Outputs: Returns the output of the forward pass of the block.\n",
        "    \"\"\"\n",
        "    identity = x\n",
        "\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.activation(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    out += self.residual_connection(identity)\n",
        "    out = self.activation(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "zC5UvxiWHVf6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can than create the model"
      ],
      "metadata": {
        "id": "8zps0LA5JaZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "  \"\"\"This class implements the ResNet-18 architecture from its components.\"\"\"\n",
        "\n",
        "  def __init__(self, activation_str=\"relu\", initialization=\"xavier_normal\"):\n",
        "    \"\"\"\n",
        "      Constructor for the ResNet18 class.\n",
        "\n",
        "      activation_str: string, default \"relu\"\n",
        "        Activation function to use.\n",
        "      initialization: string, default \"xavier_normal\"\n",
        "        Weight initialization to use.\n",
        "    \"\"\"\n",
        "    super(ResNet18, self).__init__()\n",
        "\n",
        "    self.n_classes = 10\n",
        "    self.activation_str = activation_str\n",
        "    self.initialization = initialization\n",
        "\n",
        "    self.conv1 = nn.Conv2d(4, 64, 3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._create_layer(64, 64) \n",
        "    self.layer2 = self._create_layer(64, 128, conv_stride=2)\n",
        "    self.layer3 = self._create_layer(128, 256, conv_stride=2)\n",
        "    self.layer4 = self._create_layer(256, 512, conv_stride=2)  \n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.linear = nn.Linear(512, 10)\n",
        "  \n",
        "  def activation(self, input):\n",
        "    \"\"\"\n",
        "      input: Tensor\n",
        "        Input on which the activation is applied.\n",
        "\n",
        "      Output: Result of activation function applied on input.\n",
        "        E.g. if self.activation_str is \"relu\", return relu(input).\n",
        "    \"\"\"\n",
        "    if self.activation_str == \"relu\":\n",
        "      return torch.relu(input)\n",
        "    elif self.activation_str == \"tanh\":\n",
        "      return torch.tanh(input)\n",
        "    else:\n",
        "      raise Exception(\"Invalid activation\")\n",
        "\n",
        "  def _create_layer(self, in_channels, channels, conv_stride=1):\n",
        "    \"\"\"\n",
        "      in_channels: int\n",
        "        Number of input channels present in the input to the layer.\n",
        "      out_channels: int\n",
        "        Number of output channels for the layer, i.e., the number of filters.\n",
        "      conv_stride: int, default 1\n",
        "        Stride of the first convolution layer in the block and the downsampling convolution (if required).\n",
        "\n",
        "      Outputs: Returns an nn.Sequential object giving a \"layer\" of the ResNet, consisting of 2 blocks each.\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        ResidualBlock(in_channels, channels, conv_stride=conv_stride, activation_str=self.activation_str, initialization=self.initialization),\n",
        "        ResidualBlock(channels, channels, conv_stride=1, activation_str=self.activation_str, initialization=self.initialization)\n",
        "    )\n",
        "\n",
        "  def get_first_conv_layer_filters(self):\n",
        "    \"\"\"\n",
        "      Outputs: Returns the filters in the first convolution layer.\n",
        "    \"\"\"\n",
        "    return self.conv1.weight.clone().cpu().detach().numpy()\n",
        "\n",
        "  def get_last_conv_layer_filters(self):\n",
        "    \"\"\"\n",
        "      Outputs: Returns the filters in the last convolution layer.\n",
        "    \"\"\"\n",
        "    return list(self.layer4.modules())[1].conv2.weight.clone().cpu().detach().numpy()\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "      x: Tensor\n",
        "        Input to the network.\n",
        "\n",
        "      Outputs: Returns the output of the forward pass of the network.\n",
        "    \"\"\"\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.activation(out)\n",
        "\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    \n",
        "    out = self.avgpool(out)\n",
        "    out = torch.flatten(out, 1)\n",
        "    out = self.linear(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "PQEYJqEnIoeS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a data loader for the dataset we created"
      ],
      "metadata": {
        "id": "BezckxNEIt0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter we will use\n",
        "activation_str = \"relu\"\n",
        "initialization = \"xavier_normal\""
      ],
      "metadata": {
        "id": "p9T2Rjk8Irxk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(epoch, model, train_loader, criterion, optimizer):\n",
        "  \"\"\"\n",
        "    epoch: int\n",
        "      Number of the current training epoch (starting from 0).\n",
        "    model: ResNet18\n",
        "      The model to train, which is an instance of the ResNet18 class.\n",
        "    train_loader: DataLoader\n",
        "      The training dataloader.\n",
        "    criterion: Module\n",
        "      A Module object that evaluates the crossentropy loss.\n",
        "    optimizer: Optimizer\n",
        "      An Optimizer object for the Adam optimizer.\n",
        "\n",
        "    Outputs: Returns average train_acc and train_loss for the current epoch.\n",
        "  \"\"\"\n",
        "  train_acc = 0.\n",
        "  train_loss = 0.\n",
        "  nb_data = 0 \n",
        "  model.train()\n",
        "  for inputs, labels in train_loader:\n",
        "      # Get input:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      # Zeros the parameter gradient\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # Foward + backward + optimize\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Get stats\n",
        "      train_loss += loss.item()\n",
        "      _, pred = torch.max(outputs.data, 1)\n",
        "      train_acc += (pred == labels).sum().item()\n",
        "      nb_data += labels.size(0)\n",
        "\n",
        "  train_loss = train_loss / len(train_loader)\n",
        "  train_acc = train_acc / nb_data\n",
        "\n",
        "  print(f\"Epoch: {epoch} | Train Acc: {train_acc:.6f} | Train Loss: {train_loss:.6f}\")\n",
        "  return train_acc, train_loss\n",
        "\n",
        "def valid_loop(epoch, model, val_loader, criterion):\n",
        "  \"\"\"\n",
        "    epoch: int\n",
        "      Number of the current epoch (starting from 0).\n",
        "    model: ResNet18\n",
        "      The model to train, which is an instance of the ResNet18 class.\n",
        "    val_loader: DataLoader\n",
        "      The validation dataloader.\n",
        "    criterion: Module\n",
        "      A Module object that evaluates the crossentropy loss.\n",
        "\n",
        "    Outputs: Returns average val_acc and val_loss for the current epoch.\n",
        "  \"\"\"\n",
        "  val_acc = 0.\n",
        "  val_loss = 0.\n",
        "  nb_data = 0\n",
        "\n",
        "  model.eval()\n",
        "  for inputs, labels in val_loader:\n",
        "      # Get input:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      \n",
        "      # Foward + backward + optimize\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # Get stats\n",
        "      val_loss += loss.item()\n",
        "      _, pred = torch.max(outputs.data, 1)\n",
        "      val_acc += (pred == labels).sum().item()\n",
        "      nb_data += labels.size(0)\n",
        "\n",
        "  val_loss = val_loss / len(val_loader)\n",
        "  val_acc = val_acc / nb_data\n",
        "\n",
        "  print(f\"Epoch: {epoch} | Val Acc: {val_acc:.6f}   | Val Loss: {val_loss:.6f}\")\n",
        "  return val_acc, val_loss"
      ],
      "metadata": {
        "id": "YrcVRaAJJtsR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "if __name__ == \"__main__\":\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "  train_accs, train_losses, val_accs, val_losses = [], [], [], []\n",
        "  n_epochs = 25\n",
        "\n",
        "  model = ResNet18(\n",
        "    activation_str=activation_str,\n",
        "    initialization=initialization\n",
        "  ).to(device)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "  for epoch in range(n_epochs):\n",
        "    # Training\n",
        "    train_acc, train_loss = train_loop(epoch, model, train_loader, criterion, optimizer)\n",
        "    train_accs.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validation\n",
        "    val_acc, val_loss = valid_loop(epoch, model, val_loader, criterion)\n",
        "    val_accs.append(val_acc)\n",
        "    val_losses.append(val_loss)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjOLei3SJn6v",
        "outputId": "47923d20-f493-4a02-ba29-92ea6320c9ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Acc: 0.375000 | Train Loss: 2.266934\n",
            "Epoch: 0 | Val Acc: 0.500000   | Val Loss: 2.936660\n",
            "Epoch: 1 | Train Acc: 0.458333 | Train Loss: 1.434008\n",
            "Epoch: 1 | Val Acc: 0.500000   | Val Loss: 3.821058\n",
            "Epoch: 2 | Train Acc: 0.583333 | Train Loss: 1.031421\n",
            "Epoch: 2 | Val Acc: 0.500000   | Val Loss: 1.956096\n",
            "Epoch: 3 | Train Acc: 0.583333 | Train Loss: 0.872833\n",
            "Epoch: 3 | Val Acc: 0.166667   | Val Loss: 1.847805\n",
            "Epoch: 4 | Train Acc: 0.666667 | Train Loss: 0.705132\n",
            "Epoch: 4 | Val Acc: 0.333333   | Val Loss: 1.559400\n",
            "Epoch: 5 | Train Acc: 0.791667 | Train Loss: 0.572029\n",
            "Epoch: 5 | Val Acc: 0.333333   | Val Loss: 1.330200\n",
            "Epoch: 6 | Train Acc: 0.833333 | Train Loss: 0.446711\n",
            "Epoch: 6 | Val Acc: 0.500000   | Val Loss: 1.427253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    torch.save(model, \"resnet18\")"
      ],
      "metadata": {
        "id": "JkE0SOY3JxpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    model = torch.load(\"resnet18\")"
      ],
      "metadata": {
        "id": "L9LO8nisJzy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see if the model learn something"
      ],
      "metadata": {
        "id": "CBEIn2-pJ2Cz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QqC_niU2J60I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can finaly look how the model extract this information by looking at the learned filter"
      ],
      "metadata": {
        "id": "ryP-HL08J8pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For Q 3.6\n",
        "if __name__ == \"__main__\":\n",
        "  vis_image = None\n",
        "  for data, labels in val_loader:\n",
        "    vis_image = data[12].unsqueeze(0)\n",
        "    break\n",
        "\n",
        "    # import pickle\n",
        "    # vis_image = pickle.load(open(\"vis_image.pkl\", \"rb\")).to(device)\n",
        "    # plt.imshow(vis_image.squeeze().permute(1, 2, 0).cpu().detach().numpy())\n",
        "\n",
        "    plt.imshow(vis_image.squeeze().permute(1, 2, 0).cpu().detach().numpy())\n"
      ],
      "metadata": {
        "id": "yZFXNbJjKRN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First layer"
      ],
      "metadata": {
        "id": "DZAgV1PjKaJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_filter(filters, n_filter_to_display=6):\n",
        "    # Normalize \n",
        "    f_min, f_max = filters.max(), filters.min()\n",
        "    filters = (filters - f_min) / (f_max - f_min)\n",
        "\n",
        "    i_idx = 1\n",
        "    for f_idx in range(n_filter_to_display):\n",
        "        filter = filters[f_idx, :, :, :]\n",
        "        for p_idx in range(3):\n",
        "            ax = plt.subplot(n_filter_to_display, 3, i_idx)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            # Plot\n",
        "            plt.imshow(filter[p_idx,:,:], cmap='gray')\n",
        "            i_idx += 1\n",
        "    plt.show()\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    print(\"First layer filters\")\n",
        "    first_filters = model.get_first_conv_layer_filters()\n",
        "    print_filter(first_filters)"
      ],
      "metadata": {
        "id": "mJ3Xegc2KfN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Last layer filters\")\n",
        "    last_filters = model.get_last_conv_layer_filters()\n",
        "    print_filter(last_filters)"
      ],
      "metadata": {
        "id": "RYjeVJRkKg1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let see what the graph look like with those filter"
      ],
      "metadata": {
        "id": "WHEW5UQdKhw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Fin output size\n",
        "    nb_img, channel, dim_x_img, dim_y_img = vis_image.shape\n",
        "    dim_out = (dim_x_img-3)//1 + 1\n",
        "\n",
        "    output = np.zeros((64, dim_out, dim_out))\n",
        "\n",
        "    for filter_idx in range(first_filters.shape[0]):\n",
        "        filter = first_filters[filter_idx]\n",
        "\n",
        "        for channel_i in range(filter.shape[0]):\n",
        "            # Apply kernel\n",
        "            kernel = filter[channel_i]\n",
        "            img = vis_image[0, channel_i].numpy()\n",
        "            for i in range(0, dim_out):\n",
        "                for j in range(0, dim_out):\n",
        "                    # Select part of the img\n",
        "                    img_patch = img[i:i+3, j:j+3]\n",
        "                    # Apply kernel\n",
        "                    kernel_output = np.multiply(img_patch, kernel)\n",
        "                    kernel_output = np.sum(kernel_output)\n",
        "                    # Save output\n",
        "                    output[filter_idx, i, j] = kernel_output\n",
        "\n",
        "    from matplotlib.pyplot import figure\n",
        "    figure(figsize=(10,10))\n",
        "\n",
        "    ax = [plt.subplot(8,8,i+1) for i in range(64)]\n",
        "\n",
        "    for i, a in enumerate(ax):\n",
        "        a.set_xticks([])\n",
        "        a.set_yticks([])\n",
        "\n",
        "        a.imshow(output[i,:,:], cmap='gray')\n",
        "\n",
        "    plt.subplots_adjust(wspace=0., hspace=0.1)\n"
      ],
      "metadata": {
        "id": "KsR40u58KWYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last layer"
      ],
      "metadata": {
        "id": "9fQXFdM0KYvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    model_extract_last_features = create_feature_extractor(model, {\"layer4\": \"layer4\"})\n",
        "    out = model_extract_last_features(vis_image.to(device))\n",
        "    out['layer4'].shape\n",
        "\n",
        "    figure(figsize=(10,10))\n",
        "\n",
        "    ax = [plt.subplot(8,8,i+1) for i in range(64)]\n",
        "\n",
        "    for i, a in enumerate(ax):\n",
        "        a.set_xticks([])\n",
        "        a.set_yticks([])\n",
        "\n",
        "        image = out['layer4'].cpu().detach().numpy()[0, i,:,:]\n",
        "        a.imshow(image, cmap='gray')\n",
        "\n",
        "    plt.subplots_adjust(wspace=0., hspace=0.1)"
      ],
      "metadata": {
        "id": "Ny6RkagGKYR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's trade some stock and loose money, but in style hehe"
      ],
      "metadata": {
        "id": "HGfi9001Krot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "zK2F0__TKyZ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}