{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPZyoR3qz7pc/bhNWJ5fb1I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guthi1/technical-analysis-trading-dumpster-fire/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PolyFinances article"
      ],
      "metadata": {
        "id": "TGZQ-Jkye0BQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO: Explain de situation"
      ],
      "metadata": {
        "id": "F3iLBE-1e3Ns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF5x7nDEdY9x"
      },
      "outputs": [],
      "source": [
        "# Install required librairy\n",
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import numpy as np\n",
        "import yfinance as yf"
      ],
      "metadata": {
        "id": "zD_g1JuKfx5z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG = True\n",
        "DATA_DIR = \"data/\"\n",
        "DATA_CANDLE = \"data/candle/\"\n",
        "DATA_NORMAL = \"data/normal/\"\n",
        "!mkdir data\n",
        "!mkdir data/candle\n",
        "!mkdir data/normal\n",
        "PRICE_INTERVAL = 2 # In minute, Must be in: 1m,2m,5m,15m,30m,60m,90m\n",
        "WINDOWS_INTERVAL = 60 # In minute, must be > than PRICE_INTERVAL\n",
        "assert WINDOWS_INTERVAL > PRICE_INTERVAL, \"window for analysis must be greater than the price interval\"\n",
        "\n",
        "HOLD = 0\n",
        "BUY = 1\n",
        "SELL = 2"
      ],
      "metadata": {
        "id": "wuce5Hq4ojJ-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataset"
      ],
      "metadata": {
        "id": "1KK0lczQoX2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data\n",
        "data = yf.download(  # or pdr.get_data_yahoo(...\n",
        "        # tickers list or string as well\n",
        "        tickers = \"SPY AAPL MSFT TSLA GE F AMZN AQN TD\",\n",
        "        # use \"period\" instead of start/end\n",
        "        # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
        "        # (optional, default is '1mo')\n",
        "        period = \"5d\",\n",
        "        # fetch data by interval (including intraday if period < 60 days)\n",
        "        # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
        "        interval = f\"{PRICE_INTERVAL}m\",\n",
        "        # group by ticker (to access via data['SPY'])\n",
        "        # (optional, default is 'column')\n",
        "        group_by = 'ticker',\n",
        "        # attempt repair of missing data or currency mixups e.g. $/cents\n",
        "        repair = True,\n",
        "        # use threads for mass downloading\n",
        "        threads = True\n",
        "    )\n",
        "\n",
        "print(f\"Number of row: {len(data)}\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "calvm5Tdd9Ll",
        "outputId": "38579174-f95a-43cd-8b08-53c4e1dab1ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  9 of 9 completed\n",
            "Number of row: 976\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       AQN                                                F  \\\n",
              "                      Open    High     Low  Close Adj Close  Volume    Open   \n",
              "Datetime                                                                      \n",
              "2023-01-09 09:30:00  7.270  7.3200  7.2700  7.275     7.275  175230  12.740   \n",
              "2023-01-09 09:32:00  7.275  7.2750  7.2307  7.240     7.240   27923  12.720   \n",
              "2023-01-09 09:34:00  7.240  7.2422  7.2000  7.215     7.215   55662  12.650   \n",
              "2023-01-09 09:36:00  7.220  7.2400  7.2100  7.225     7.225  110361  12.690   \n",
              "2023-01-09 09:38:00  7.230  7.2400  7.2100  7.230     7.230   69507  12.625   \n",
              "\n",
              "                                            ...       AMZN             \\\n",
              "                      High    Low    Close  ...        Low      Close   \n",
              "Datetime                                    ...                         \n",
              "2023-01-09 09:30:00  12.76  12.67  12.7101  ...  87.459999  88.410004   \n",
              "2023-01-09 09:32:00  12.73  12.65  12.6515  ...  88.150101  88.500000   \n",
              "2023-01-09 09:34:00  12.70  12.64  12.6850  ...  88.290001  88.470001   \n",
              "2023-01-09 09:36:00  12.70  12.62  12.6200  ...  87.909897  88.157303   \n",
              "2023-01-09 09:38:00  12.66  12.58  12.5950  ...  88.120003  88.394997   \n",
              "\n",
              "                                                SPY                          \\\n",
              "                     Adj Close   Volume        Open        High         Low   \n",
              "Datetime                                                                      \n",
              "2023-01-09 09:30:00  88.410004  3916487  390.369995  390.450012  389.839996   \n",
              "2023-01-09 09:32:00  88.500000  1074282  390.440002  390.839996  390.130005   \n",
              "2023-01-09 09:34:00  88.470001   712346  390.160004  390.309998  389.709991   \n",
              "2023-01-09 09:36:00  88.157303   985453  389.829987  389.959991  389.420013   \n",
              "2023-01-09 09:38:00  88.394997   708215  389.630005  389.920105  389.350006   \n",
              "\n",
              "                                                      \n",
              "                          Close   Adj Close   Volume  \n",
              "Datetime                                              \n",
              "2023-01-09 09:30:00  390.410004  390.410004  2402676  \n",
              "2023-01-09 09:32:00  390.170013  390.170013   487845  \n",
              "2023-01-09 09:34:00  389.825012  389.825012   501256  \n",
              "2023-01-09 09:36:00  389.639709  389.639709   451951  \n",
              "2023-01-09 09:38:00  389.880005  389.880005   367161  \n",
              "\n",
              "[5 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-719e16a3-29d4-42d3-acf2-006cb0236f15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">AQN</th>\n",
              "      <th colspan=\"4\" halign=\"left\">F</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"4\" halign=\"left\">AMZN</th>\n",
              "      <th colspan=\"6\" halign=\"left\">SPY</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-09 09:30:00</th>\n",
              "      <td>7.270</td>\n",
              "      <td>7.3200</td>\n",
              "      <td>7.2700</td>\n",
              "      <td>7.275</td>\n",
              "      <td>7.275</td>\n",
              "      <td>175230</td>\n",
              "      <td>12.740</td>\n",
              "      <td>12.76</td>\n",
              "      <td>12.67</td>\n",
              "      <td>12.7101</td>\n",
              "      <td>...</td>\n",
              "      <td>87.459999</td>\n",
              "      <td>88.410004</td>\n",
              "      <td>88.410004</td>\n",
              "      <td>3916487</td>\n",
              "      <td>390.369995</td>\n",
              "      <td>390.450012</td>\n",
              "      <td>389.839996</td>\n",
              "      <td>390.410004</td>\n",
              "      <td>390.410004</td>\n",
              "      <td>2402676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09 09:32:00</th>\n",
              "      <td>7.275</td>\n",
              "      <td>7.2750</td>\n",
              "      <td>7.2307</td>\n",
              "      <td>7.240</td>\n",
              "      <td>7.240</td>\n",
              "      <td>27923</td>\n",
              "      <td>12.720</td>\n",
              "      <td>12.73</td>\n",
              "      <td>12.65</td>\n",
              "      <td>12.6515</td>\n",
              "      <td>...</td>\n",
              "      <td>88.150101</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>1074282</td>\n",
              "      <td>390.440002</td>\n",
              "      <td>390.839996</td>\n",
              "      <td>390.130005</td>\n",
              "      <td>390.170013</td>\n",
              "      <td>390.170013</td>\n",
              "      <td>487845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09 09:34:00</th>\n",
              "      <td>7.240</td>\n",
              "      <td>7.2422</td>\n",
              "      <td>7.2000</td>\n",
              "      <td>7.215</td>\n",
              "      <td>7.215</td>\n",
              "      <td>55662</td>\n",
              "      <td>12.650</td>\n",
              "      <td>12.70</td>\n",
              "      <td>12.64</td>\n",
              "      <td>12.6850</td>\n",
              "      <td>...</td>\n",
              "      <td>88.290001</td>\n",
              "      <td>88.470001</td>\n",
              "      <td>88.470001</td>\n",
              "      <td>712346</td>\n",
              "      <td>390.160004</td>\n",
              "      <td>390.309998</td>\n",
              "      <td>389.709991</td>\n",
              "      <td>389.825012</td>\n",
              "      <td>389.825012</td>\n",
              "      <td>501256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09 09:36:00</th>\n",
              "      <td>7.220</td>\n",
              "      <td>7.2400</td>\n",
              "      <td>7.2100</td>\n",
              "      <td>7.225</td>\n",
              "      <td>7.225</td>\n",
              "      <td>110361</td>\n",
              "      <td>12.690</td>\n",
              "      <td>12.70</td>\n",
              "      <td>12.62</td>\n",
              "      <td>12.6200</td>\n",
              "      <td>...</td>\n",
              "      <td>87.909897</td>\n",
              "      <td>88.157303</td>\n",
              "      <td>88.157303</td>\n",
              "      <td>985453</td>\n",
              "      <td>389.829987</td>\n",
              "      <td>389.959991</td>\n",
              "      <td>389.420013</td>\n",
              "      <td>389.639709</td>\n",
              "      <td>389.639709</td>\n",
              "      <td>451951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09 09:38:00</th>\n",
              "      <td>7.230</td>\n",
              "      <td>7.2400</td>\n",
              "      <td>7.2100</td>\n",
              "      <td>7.230</td>\n",
              "      <td>7.230</td>\n",
              "      <td>69507</td>\n",
              "      <td>12.625</td>\n",
              "      <td>12.66</td>\n",
              "      <td>12.58</td>\n",
              "      <td>12.5950</td>\n",
              "      <td>...</td>\n",
              "      <td>88.120003</td>\n",
              "      <td>88.394997</td>\n",
              "      <td>88.394997</td>\n",
              "      <td>708215</td>\n",
              "      <td>389.630005</td>\n",
              "      <td>389.920105</td>\n",
              "      <td>389.350006</td>\n",
              "      <td>389.880005</td>\n",
              "      <td>389.880005</td>\n",
              "      <td>367161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-719e16a3-29d4-42d3-acf2-006cb0236f15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-719e16a3-29d4-42d3-acf2-006cb0236f15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-719e16a3-29d4-42d3-acf2-006cb0236f15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build dataset"
      ],
      "metadata": {
        "id": "40KdeKTSD948"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_number = 0\n",
        "# Dataframe to save the value we need\n",
        "dataset={\"candle_path\": [], \"normal_path\": [], \"action\": [], \"info\": [], \"filename\": []}"
      ],
      "metadata": {
        "id": "TmFepAAuGoKt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try it for ford first\n",
        "ticker = \"F\"\n",
        "ticker_data = data[ticker]\n",
        "ticker_data.dropna() # Sanity check\n",
        "ticker_data[\"datetime\"] = ticker_data.index\n",
        "\n",
        "# Find Dataset range\n",
        "day = ticker_data['datetime'].min()\n",
        "last_end = ticker_data['datetime'].max()\n",
        "if DEBUG: print(f\"From {day} to {last_end}\")\n",
        "\n",
        "plt.close()\n",
        "\n",
        "while day <= last_end:\n",
        "    if DEBUG: print(f\"{day}\")\n",
        "\n",
        "    start_window = day\n",
        "    end_window = start_window + datetime.timedelta(minutes=WINDOWS_INTERVAL)\n",
        "    end_of_day = day + datetime.timedelta(hours=6.5)\n",
        "\n",
        "    while start_window < end_of_day - datetime.timedelta(minutes=WINDOWS_INTERVAL):\n",
        "        if DEBUG: print(f\"    {start_window}\")\n",
        "\n",
        "        # Create a mask for the desired window\n",
        "        mask = (ticker_data['datetime'] > start_window) & (ticker_data['datetime'] <= end_window)\n",
        "        window_data = ticker_data.loc[mask]\n",
        "        \"\"\" TODO: This could be change to something smarter \"\"\"\n",
        "        mean_close = window_data.Close.mean()\n",
        "\n",
        "        # \"up\" dataframe will store the stock_prices when the closing stock \n",
        "        # price is greater than or equal to the opening stock prices\n",
        "        up = window_data[window_data.Close >= window_data.Open]\n",
        "        col1 = 'red'\n",
        "\n",
        "        # \"down\" dataframe will store the stock_prices when the closing stock \n",
        "        # price is lesser than the opening stock prices\n",
        "        down = window_data[window_data.Close < window_data.Open]\n",
        "        col2 = 'blue'\n",
        "\n",
        "        # Setting width of candlestick elements\n",
        "        width = .0005\n",
        "        width2 = .00008\n",
        "\n",
        "        # Plotting up prices of the stock\n",
        "        plt.bar(up.datetime, up.Close-up.Open, width, bottom=up.Open, color=col1)\n",
        "        plt.bar(up.datetime, up.High-up.Close, width2, bottom=up.Close, color=col1)\n",
        "        plt.bar(up.datetime, up.Low-up.Open, width2, bottom=up.Open, color=col1)\n",
        "\n",
        "        # Plotting down prices of the stock\n",
        "        plt.bar(down.datetime, down.Close-down.Open, width, bottom=down.Open, color=col2)\n",
        "        plt.bar(down.datetime, down.High-down.Open, width2, bottom=down.Open, color=col2)\n",
        "        plt.bar(down.datetime, down.Low-down.Close, width2, bottom=down.Close, color=col2)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Saving the candle plot\n",
        "        plt_name = f\"{plot_number}.png\"\n",
        "        plt.savefig(f\"{DATA_CANDLE}{plt_name}\", format=\"png\")\n",
        "        plt.close()    \n",
        "        dataset[\"filename\"].append(plt_name)\n",
        "        dataset[\"candle_path\"].append(DATA_CANDLE)\n",
        "\n",
        "        # Plotting the time series of given dataframe\n",
        "        plt.plot(window_data[\"datetime\"], window_data[\"Adj Close\"])\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Saving the normal plot\n",
        "        plt_name = f\"{DATA_NORMAL}{plot_number}.png\"\n",
        "        plt.savefig(plt_name, format=\"png\")\n",
        "        plt.close()    \n",
        "        dataset[\"normal_path\"].append(DATA_CANDLE)\n",
        "        \n",
        "        # Update var\n",
        "        plot_number += 1\n",
        "        start_window = end_window\n",
        "        end_window = start_window + datetime.timedelta(minutes=WINDOWS_INTERVAL)\n",
        "\n",
        "        # Check if it's a hold, buy and sold\n",
        "        \"\"\" TODO: This could be change to something smarter \"\"\"\n",
        "        mask = (ticker_data['datetime'] > start_window) & (ticker_data['datetime'] <= end_window)\n",
        "        window_data = ticker_data.loc[mask]\n",
        "        mean_close_next_interval = window_data.Close.mean()\n",
        "\n",
        "        diff = mean_close_next_interval / mean_close\n",
        "        if diff > 1.002:\n",
        "            dataset[\"action\"].append(BUY)\n",
        "        elif diff < 0.998:\n",
        "            dataset[\"action\"].append(SELL)\n",
        "        else:\n",
        "            dataset[\"action\"].append(HOLD)\n",
        "\n",
        "        # For debugging later\n",
        "        dataset[\"info\"].append(f\"{ticker}: {start_window}\")\n",
        "\n",
        "    day += datetime.timedelta(days=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy7tT02qyNNq",
        "outputId": "06bf2bcd-776a-4de1-f686-b763b3fa466a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-c69a98fb9b34>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ticker_data[\"datetime\"] = ticker_data.index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From 2023-01-09 09:30:00 to 2023-01-13 16:00:00\n",
            "2023-01-09 09:30:00\n",
            "    2023-01-09 09:30:00\n",
            "    2023-01-09 10:30:00\n",
            "    2023-01-09 11:30:00\n",
            "    2023-01-09 12:30:00\n",
            "    2023-01-09 13:30:00\n",
            "    2023-01-09 14:30:00\n",
            "2023-01-10 09:30:00\n",
            "    2023-01-10 09:30:00\n",
            "    2023-01-10 10:30:00\n",
            "    2023-01-10 11:30:00\n",
            "    2023-01-10 12:30:00\n",
            "    2023-01-10 13:30:00\n",
            "    2023-01-10 14:30:00\n",
            "2023-01-11 09:30:00\n",
            "    2023-01-11 09:30:00\n",
            "    2023-01-11 10:30:00\n",
            "    2023-01-11 11:30:00\n",
            "    2023-01-11 12:30:00\n",
            "    2023-01-11 13:30:00\n",
            "    2023-01-11 14:30:00\n",
            "2023-01-12 09:30:00\n",
            "    2023-01-12 09:30:00\n",
            "    2023-01-12 10:30:00\n",
            "    2023-01-12 11:30:00\n",
            "    2023-01-12 12:30:00\n",
            "    2023-01-12 13:30:00\n",
            "    2023-01-12 14:30:00\n",
            "2023-01-13 09:30:00\n",
            "    2023-01-13 09:30:00\n",
            "    2023-01-13 10:30:00\n",
            "    2023-01-13 11:30:00\n",
            "    2023-01-13 12:30:00\n",
            "    2023-01-13 13:30:00\n",
            "    2023-01-13 14:30:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.DataFrame(data=dataset)\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pLxH4U3nFKii",
        "outputId": "c8775397-f417-43d0-9287-c7208e655530"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    candle_path   normal_path  action                    info filename\n",
              "0  data/candle/  data/candle/       1  F: 2023-01-09 10:30:00    0.png\n",
              "1  data/candle/  data/candle/       1  F: 2023-01-09 11:30:00    1.png\n",
              "2  data/candle/  data/candle/       2  F: 2023-01-09 12:30:00    2.png\n",
              "3  data/candle/  data/candle/       0  F: 2023-01-09 13:30:00    3.png\n",
              "4  data/candle/  data/candle/       2  F: 2023-01-09 14:30:00    4.png"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91ebeee8-2515-4e5e-a96e-3aefc1015f28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>candle_path</th>\n",
              "      <th>normal_path</th>\n",
              "      <th>action</th>\n",
              "      <th>info</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/candle/</td>\n",
              "      <td>data/candle/</td>\n",
              "      <td>1</td>\n",
              "      <td>F: 2023-01-09 10:30:00</td>\n",
              "      <td>0.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/candle/</td>\n",
              "      <td>data/candle/</td>\n",
              "      <td>1</td>\n",
              "      <td>F: 2023-01-09 11:30:00</td>\n",
              "      <td>1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/candle/</td>\n",
              "      <td>data/candle/</td>\n",
              "      <td>2</td>\n",
              "      <td>F: 2023-01-09 12:30:00</td>\n",
              "      <td>2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/candle/</td>\n",
              "      <td>data/candle/</td>\n",
              "      <td>0</td>\n",
              "      <td>F: 2023-01-09 13:30:00</td>\n",
              "      <td>3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/candle/</td>\n",
              "      <td>data/candle/</td>\n",
              "      <td>2</td>\n",
              "      <td>F: 2023-01-09 14:30:00</td>\n",
              "      <td>4.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91ebeee8-2515-4e5e-a96e-3aefc1015f28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91ebeee8-2515-4e5e-a96e-3aefc1015f28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91ebeee8-2515-4e5e-a96e-3aefc1015f28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "PCYx7Z2UHTED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.io import read_image\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Fix random seed\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "k3eRQkNiIeqc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a data loader for the dataset we created"
      ],
      "metadata": {
        "id": "GOlnoVvLI4Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TechnicalAnalysisDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, chart_dir, transform=None):\n",
        "        self.df = data\n",
        "        self.img_dir = chart_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.df.iloc[idx][\"filename\"])\n",
        "        image = read_image(img_path)\n",
        "        image = image / 255\n",
        "        label = self.df.iloc[idx][\"action\"]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "fa2N7CRBI6J2"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our dataset, we will need to split it in a training and validation set and we will need a data loader to be able to have minibatch."
      ],
      "metadata": {
        "id": "g_JWp5T3Sfdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(df, frac=0.2):\n",
        "    \n",
        "    # get random sample \n",
        "    test = df.sample(frac=frac, axis=0)\n",
        "\n",
        "    # get everything but the test sample\n",
        "    train = df.drop(index=test.index)\n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "Qap0JMKVTumk"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset, test_dataset = train_test_split(dataset)\n",
        "\n",
        "train_technical_analysis_dataset = TechnicalAnalysisDataset(train_dataset, DATA_CANDLE, transform=resize_transform)\n",
        "test_technical_analysis_dataset = TechnicalAnalysisDataset(test_dataset, DATA_CANDLE, transform=resize_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_technical_analysis_dataset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "      test_technical_analysis_dataset, batch_size=128, shuffle=False, num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "mm-lK_MoSuH_"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check\n",
        "img, label = train_technical_analysis_dataset.__getitem__(1)\n",
        "img = img.permute(1, 2, 0)\n",
        "print(img.shape)\n",
        "print(label)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "kVTEidsNOLEv",
        "outputId": "1c4a77e1-2f9b-49e7-fd6a-15c3e4e19eed"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 256, 4])\n",
            "2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training architecture"
      ],
      "metadata": {
        "id": "RiRBWJcjeiwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(epoch, model, train_loader, criterion, optimizer):\n",
        "  \"\"\"\n",
        "    epoch: int\n",
        "      Number of the current training epoch (starting from 0).\n",
        "    model: ResNet18\n",
        "      The model to train, which is an instance of the ResNet18 class.\n",
        "    train_loader: DataLoader\n",
        "      The training dataloader.\n",
        "    criterion: Module\n",
        "      A Module object that evaluates the crossentropy loss.\n",
        "    optimizer: Optimizer\n",
        "      An Optimizer object for the Adam optimizer.\n",
        "\n",
        "    Outputs: Returns average train_acc and train_loss for the current epoch.\n",
        "  \"\"\"\n",
        "  train_acc = 0.\n",
        "  train_loss = 0.\n",
        "  nb_data = 0 \n",
        "  model.train()\n",
        "  for inputs, labels in train_loader:\n",
        "      # Get input:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      # Zeros the parameter gradient\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # Foward + backward + optimize\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Get stats\n",
        "      train_loss += loss.item()\n",
        "      _, pred = torch.max(outputs.data, 1)\n",
        "      train_acc += (pred == labels).sum().item()\n",
        "      nb_data += labels.size(0)\n",
        "\n",
        "  train_loss = train_loss / len(train_loader)\n",
        "  train_acc = train_acc / nb_data\n",
        "\n",
        "  print(f\"Epoch: {epoch} | Train Acc: {train_acc:.6f} | Train Loss: {train_loss:.6f}\")\n",
        "  return train_acc, train_loss\n",
        "\n",
        "def valid_loop(epoch, model, val_loader, criterion):\n",
        "  \"\"\"\n",
        "    epoch: int\n",
        "      Number of the current epoch (starting from 0).\n",
        "    model: ResNet18\n",
        "      The model to train, which is an instance of the ResNet18 class.\n",
        "    val_loader: DataLoader\n",
        "      The validation dataloader.\n",
        "    criterion: Module\n",
        "      A Module object that evaluates the crossentropy loss.\n",
        "\n",
        "    Outputs: Returns average val_acc and val_loss for the current epoch.\n",
        "  \"\"\"\n",
        "  val_acc = 0.\n",
        "  val_loss = 0.\n",
        "  nb_data = 0\n",
        "\n",
        "  model.eval()\n",
        "  for inputs, labels in val_loader:\n",
        "      # Get input:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      \n",
        "      # Foward + backward + optimize\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # Get stats\n",
        "      val_loss += loss.item()\n",
        "      _, pred = torch.max(outputs.data, 1)\n",
        "      val_acc += (pred == labels).sum().item()\n",
        "      nb_data += labels.size(0)\n",
        "\n",
        "  val_loss = val_loss / len(val_loader)\n",
        "  val_acc = val_acc / nb_data\n",
        "\n",
        "  print(f\"Epoch: {epoch} | Val Acc: {val_acc:.6f}   | Val Loss: {val_loss:.6f}\")\n",
        "  return val_acc, val_loss"
      ],
      "metadata": {
        "id": "4oZXbuHdekvk"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models\n",
        "\n"
      ],
      "metadata": {
        "id": "YuBwOTFGchEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "-DlQCZrNfwZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.dropout import Dropout\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(4*256*256, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.Linear(512, 254),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.Linear(254, 3)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.flatten(start_dim=1)\n",
        "        out = self.model(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "LkD1kBpGcsxF"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "if __name__ == \"__main__\":\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "  train_accs, train_losses, val_accs, val_losses = [], [], [], []\n",
        "  n_epochs = 12\n",
        "\n",
        "  mlp = MLP().to(device)\n",
        "  nb_params = sum(p.numel() for p in mlp.parameters())\n",
        "  print(mlp)\n",
        "  print(f\"Number of parameter: {nb_params}\")\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(mlp.parameters())\n",
        "\n",
        "  tic = time.perf_counter()\n",
        "  for epoch in range(n_epochs):\n",
        "    # Training\n",
        "    train_acc, train_loss = train_loop(epoch, mlp, train_loader, criterion, optimizer)\n",
        "    train_accs.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validation\n",
        "    val_acc, val_loss = valid_loop(epoch, mlp, val_loader, criterion)\n",
        "    val_accs.append(val_acc)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "  toc = time.perf_counter()\n",
        "  print(f\"Time to train {toc - tic:0.4f} seconds\")"
      ],
      "metadata": {
        "id": "ZMeWCMs6dKOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resnet-18"
      ],
      "metadata": {
        "id": "GSDGC_SLcjZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, we can try with Resnet-18. This might be overkill, but why not, I won't trade any real money in the end"
      ],
      "metadata": {
        "id": "CVONtmeVJFty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  \"\"\"This class implements the Residual Block used in ResNet-18.\"\"\"\n",
        "\n",
        "  def __init__(self, in_channels, channels, conv_stride=1, activation_str=\"relu\", initialization=\"xavier_normal\"):\n",
        "    \"\"\"\n",
        "      Constructor for the ResidualBlock class.\n",
        "\n",
        "      in_channels: int\n",
        "        Number of channels in the input to the block.\n",
        "      channels: int\n",
        "        Number of output channels for the block, i.e., number of filters.\n",
        "      conv_stride: int, default 1\n",
        "        Stride of the first convolution layer and downsampling convolution (if required).\n",
        "      activation_str: string, default \"relu\"\n",
        "        Activation function to use.\n",
        "      initialization: string, default \"xavier_normal\"\n",
        "        Initialization for convolution layer weights.\n",
        "    \"\"\"\n",
        "    super(ResidualBlock, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.channels = channels\n",
        "    self.conv_stride = conv_stride\n",
        "    self.activation_str = activation_str\n",
        "    self.initialization = initialization\n",
        "\n",
        "    # Define these members by replacing `None` with the correct definitions\n",
        "    self.conv1 = nn.Conv2d(in_channels, channels, 3, stride=conv_stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(channels)\n",
        "    self.conv2 = nn.Conv2d(channels, channels, 3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    self.residual_connection = self.residual(in_channels, channels, conv_stride)\n",
        "\n",
        "    # Initialize weights for conv1 and conv2\n",
        "    if initialization == \"xavier_normal\":\n",
        "      nn.init.xavier_normal_(self.conv1.weight)\n",
        "      nn.init.xavier_normal_(self.conv2.weight)\n",
        "    elif initialization == \"xavier_uniform\": \n",
        "      nn.init.xavier_uniform_(self.conv1.weight)\n",
        "      nn.init.xavier_uniform_(self.conv2.weight)\n",
        "    elif initialization == \"kaiming_normal\": \n",
        "      nn.init.kaiming_normal_(self.conv1.weight)\n",
        "      nn.init.kaiming_normal_(self.conv2.weight)\n",
        "    else:\n",
        "      raise Exception(\"Invalid initialization\")\n",
        "\n",
        "  def activation(self, input):\n",
        "    \"\"\"\n",
        "      input: Tensor\n",
        "        Input on which the activation is applied.\n",
        "\n",
        "      Output: Result of activation function applied on input.\n",
        "        E.g. if self.activation_str is \"relu\", return relu(input).\n",
        "    \"\"\"\n",
        "    if self.activation_str == \"relu\":\n",
        "      return torch.relu(input)\n",
        "    elif self.activation_str == \"tanh\":\n",
        "      return torch.tanh(input)\n",
        "    else:\n",
        "      raise Exception(\"Invalid activation\")\n",
        "\n",
        "  def residual(self, in_channels, channels, conv_stride=1):\n",
        "    \"\"\"\n",
        "      in_channels: int\n",
        "        Number of input channels in the input to the block.\n",
        "      channels: int\n",
        "        Number of output channels for the block, i.e., number of filters.\n",
        "      conv_stride: int, default 1\n",
        "        Stride to use for downsampling 1x1 convolution.\n",
        "\n",
        "      Output: Returns an nn.Sequential object which computes the identity function of the input if stride is 1\n",
        "              and the number of input channels equals the number of output channels. Otherwise, it returns an\n",
        "              nn.Sequential object that downsamples its input using a 1x1-conv of the stride specified and\n",
        "              followed by a BatchNorm2d.\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    if conv_stride != 1 or in_channels != channels:\n",
        "      layers.append(nn.Conv2d(in_channels, channels, 1, stride=conv_stride, padding=0, bias=False))\n",
        "      layers.append(nn.BatchNorm2d(channels))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "      x: Tensor\n",
        "        Input to the block.\n",
        "\n",
        "      Outputs: Returns the output of the forward pass of the block.\n",
        "    \"\"\"\n",
        "    identity = x\n",
        "\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.activation(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    out += self.residual_connection(identity)\n",
        "    out = self.activation(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "zC5UvxiWHVf6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can than create the model"
      ],
      "metadata": {
        "id": "8zps0LA5JaZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "  \"\"\"This class implements the ResNet-18 architecture from its components.\"\"\"\n",
        "\n",
        "  def __init__(self, activation_str=\"relu\", initialization=\"xavier_normal\"):\n",
        "    \"\"\"\n",
        "      Constructor for the ResNet18 class.\n",
        "\n",
        "      activation_str: string, default \"relu\"\n",
        "        Activation function to use.\n",
        "      initialization: string, default \"xavier_normal\"\n",
        "        Weight initialization to use.\n",
        "    \"\"\"\n",
        "    super(ResNet18, self).__init__()\n",
        "\n",
        "    self.n_classes = 10\n",
        "    self.activation_str = activation_str\n",
        "    self.initialization = initialization\n",
        "\n",
        "    self.conv1 = nn.Conv2d(4, 64, 3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._create_layer(64, 64) \n",
        "    self.layer2 = self._create_layer(64, 128, conv_stride=2)\n",
        "    self.layer3 = self._create_layer(128, 256, conv_stride=2)\n",
        "    self.layer4 = self._create_layer(256, 512, conv_stride=2)  \n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.linear = nn.Linear(512, 3)\n",
        "  \n",
        "  def activation(self, input):\n",
        "    \"\"\"\n",
        "      input: Tensor\n",
        "        Input on which the activation is applied.\n",
        "\n",
        "      Output: Result of activation function applied on input.\n",
        "        E.g. if self.activation_str is \"relu\", return relu(input).\n",
        "    \"\"\"\n",
        "    if self.activation_str == \"relu\":\n",
        "      return torch.relu(input)\n",
        "    elif self.activation_str == \"tanh\":\n",
        "      return torch.tanh(input)\n",
        "    else:\n",
        "      raise Exception(\"Invalid activation\")\n",
        "\n",
        "  def _create_layer(self, in_channels, channels, conv_stride=1):\n",
        "    \"\"\"\n",
        "      in_channels: int\n",
        "        Number of input channels present in the input to the layer.\n",
        "      out_channels: int\n",
        "        Number of output channels for the layer, i.e., the number of filters.\n",
        "      conv_stride: int, default 1\n",
        "        Stride of the first convolution layer in the block and the downsampling convolution (if required).\n",
        "\n",
        "      Outputs: Returns an nn.Sequential object giving a \"layer\" of the ResNet, consisting of 2 blocks each.\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        ResidualBlock(in_channels, channels, conv_stride=conv_stride, activation_str=self.activation_str, initialization=self.initialization),\n",
        "        ResidualBlock(channels, channels, conv_stride=1, activation_str=self.activation_str, initialization=self.initialization)\n",
        "    )\n",
        "\n",
        "  def get_first_conv_layer_filters(self):\n",
        "    \"\"\"\n",
        "      Outputs: Returns the filters in the first convolution layer.\n",
        "    \"\"\"\n",
        "    return self.conv1.weight.clone().cpu().detach().numpy()\n",
        "\n",
        "  def get_last_conv_layer_filters(self):\n",
        "    \"\"\"\n",
        "      Outputs: Returns the filters in the last convolution layer.\n",
        "    \"\"\"\n",
        "    return list(self.layer4.modules())[1].conv2.weight.clone().cpu().detach().numpy()\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "      x: Tensor\n",
        "        Input to the network.\n",
        "\n",
        "      Outputs: Returns the output of the forward pass of the network.\n",
        "    \"\"\"\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.activation(out)\n",
        "\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    \n",
        "    out = self.avgpool(out)\n",
        "    out = torch.flatten(out, 1)\n",
        "    out = self.linear(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "PQEYJqEnIoeS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter we will use\n",
        "activation_str = \"relu\"\n",
        "initialization = \"xavier_normal\""
      ],
      "metadata": {
        "id": "p9T2Rjk8Irxk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "if __name__ == \"__main__\":\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "  train_accs, train_losses, val_accs, val_losses = [], [], [], []\n",
        "  n_epochs = 25\n",
        "\n",
        "  model = ResNet18(\n",
        "    activation_str=activation_str,\n",
        "    initialization=initialization\n",
        "  ).to(device)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "  for epoch in range(n_epochs):\n",
        "    # Training\n",
        "    train_acc, train_loss = train_loop(epoch, model, train_loader, criterion, optimizer)\n",
        "    train_accs.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validation\n",
        "    val_acc, val_loss = valid_loop(epoch, model, val_loader, criterion)\n",
        "    val_accs.append(val_acc)\n",
        "    val_losses.append(val_loss)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjOLei3SJn6v",
        "outputId": "47923d20-f493-4a02-ba29-92ea6320c9ab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Acc: 0.375000 | Train Loss: 2.266934\n",
            "Epoch: 0 | Val Acc: 0.500000   | Val Loss: 2.936660\n",
            "Epoch: 1 | Train Acc: 0.458333 | Train Loss: 1.434008\n",
            "Epoch: 1 | Val Acc: 0.500000   | Val Loss: 3.821058\n",
            "Epoch: 2 | Train Acc: 0.583333 | Train Loss: 1.031421\n",
            "Epoch: 2 | Val Acc: 0.500000   | Val Loss: 1.956096\n",
            "Epoch: 3 | Train Acc: 0.583333 | Train Loss: 0.872833\n",
            "Epoch: 3 | Val Acc: 0.166667   | Val Loss: 1.847805\n",
            "Epoch: 4 | Train Acc: 0.666667 | Train Loss: 0.705132\n",
            "Epoch: 4 | Val Acc: 0.333333   | Val Loss: 1.559400\n",
            "Epoch: 5 | Train Acc: 0.791667 | Train Loss: 0.572029\n",
            "Epoch: 5 | Val Acc: 0.333333   | Val Loss: 1.330200\n",
            "Epoch: 6 | Train Acc: 0.833333 | Train Loss: 0.446711\n",
            "Epoch: 6 | Val Acc: 0.500000   | Val Loss: 1.427253\n",
            "Epoch: 7 | Train Acc: 1.000000 | Train Loss: 0.332901\n",
            "Epoch: 7 | Val Acc: 0.500000   | Val Loss: 1.809139\n",
            "Epoch: 8 | Train Acc: 1.000000 | Train Loss: 0.233001\n",
            "Epoch: 8 | Val Acc: 0.500000   | Val Loss: 1.962750\n",
            "Epoch: 9 | Train Acc: 1.000000 | Train Loss: 0.184717\n",
            "Epoch: 9 | Val Acc: 0.500000   | Val Loss: 1.884438\n",
            "Epoch: 10 | Train Acc: 1.000000 | Train Loss: 0.132077\n",
            "Epoch: 10 | Val Acc: 0.500000   | Val Loss: 1.789932\n",
            "Epoch: 11 | Train Acc: 1.000000 | Train Loss: 0.093176\n",
            "Epoch: 11 | Val Acc: 0.500000   | Val Loss: 1.633231\n",
            "Epoch: 12 | Train Acc: 1.000000 | Train Loss: 0.069862\n",
            "Epoch: 12 | Val Acc: 0.500000   | Val Loss: 1.485668\n",
            "Epoch: 13 | Train Acc: 1.000000 | Train Loss: 0.045308\n",
            "Epoch: 13 | Val Acc: 0.500000   | Val Loss: 1.350421\n",
            "Epoch: 14 | Train Acc: 1.000000 | Train Loss: 0.034730\n",
            "Epoch: 14 | Val Acc: 0.500000   | Val Loss: 1.314010\n",
            "Epoch: 15 | Train Acc: 1.000000 | Train Loss: 0.020887\n",
            "Epoch: 15 | Val Acc: 0.500000   | Val Loss: 1.480968\n",
            "Epoch: 16 | Train Acc: 1.000000 | Train Loss: 0.017822\n",
            "Epoch: 16 | Val Acc: 0.500000   | Val Loss: 1.802689\n",
            "Epoch: 17 | Train Acc: 1.000000 | Train Loss: 0.012764\n",
            "Epoch: 17 | Val Acc: 0.500000   | Val Loss: 2.115968\n",
            "Epoch: 18 | Train Acc: 1.000000 | Train Loss: 0.010071\n",
            "Epoch: 18 | Val Acc: 0.500000   | Val Loss: 2.173847\n",
            "Epoch: 19 | Train Acc: 1.000000 | Train Loss: 0.008766\n",
            "Epoch: 19 | Val Acc: 0.500000   | Val Loss: 1.950229\n",
            "Epoch: 20 | Train Acc: 1.000000 | Train Loss: 0.006850\n",
            "Epoch: 20 | Val Acc: 0.500000   | Val Loss: 1.590899\n",
            "Epoch: 21 | Train Acc: 1.000000 | Train Loss: 0.005979\n",
            "Epoch: 21 | Val Acc: 0.500000   | Val Loss: 1.345067\n",
            "Epoch: 22 | Train Acc: 1.000000 | Train Loss: 0.005253\n",
            "Epoch: 22 | Val Acc: 0.333333   | Val Loss: 1.252151\n",
            "Epoch: 23 | Train Acc: 1.000000 | Train Loss: 0.004425\n",
            "Epoch: 23 | Val Acc: 0.333333   | Val Loss: 1.206566\n",
            "Epoch: 24 | Train Acc: 1.000000 | Train Loss: 0.003570\n",
            "Epoch: 24 | Val Acc: 0.333333   | Val Loss: 1.140205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    torch.save(model, \"resnet18\")"
      ],
      "metadata": {
        "id": "JkE0SOY3JxpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    model = torch.load(\"resnet18\")"
      ],
      "metadata": {
        "id": "L9LO8nisJzy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see if the model learn something"
      ],
      "metadata": {
        "id": "CBEIn2-pJ2Cz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QqC_niU2J60I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can finaly look how the model extract this information by looking at the learned filter"
      ],
      "metadata": {
        "id": "ryP-HL08J8pC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First layer"
      ],
      "metadata": {
        "id": "DZAgV1PjKaJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_filter(filters, n_filter_to_display=6):\n",
        "    # Normalize \n",
        "    f_min, f_max = filters.max(), filters.min()\n",
        "    filters = (filters - f_min) / (f_max - f_min)\n",
        "\n",
        "    i_idx = 1\n",
        "    for f_idx in range(n_filter_to_display):\n",
        "        filter = filters[f_idx, :, :, :]\n",
        "        for p_idx in range(3):\n",
        "            ax = plt.subplot(n_filter_to_display, 3, i_idx)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            # Plot\n",
        "            plt.imshow(filter[p_idx,:,:], cmap='gray')\n",
        "            i_idx += 1\n",
        "    plt.show()\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    print(\"First layer filters\")\n",
        "    first_filters = model.get_first_conv_layer_filters()\n",
        "    print_filter(first_filters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "mJ3Xegc2KfN0",
        "outputId": "548e59d7-e609-4df9-9456-c36f2a280b71"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First layer filters\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 18 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAADrCAYAAABU1kLLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALN0lEQVR4nO3dS2ic5QLG8fdrhplcTNPEiVIkZBSLDBUtdLyBFAQXthtL8YIgeNmopeANEeqiIiJSL0gUpAtRENSFIF1pwFZxoSKx1HpBUwOJJrUxqTbpJM113rPtohme9+TM05Lz/23njzP0TR5nyMc3WYwxAIDLugv9AgD8f2F0AFgxOgCsGB0AVowOACtGB4BVLiVubW2NHR0dUnv69Gmp27x5s9QNDw+HycnJTIqRJJfLxUKhILXd3d1St7S0JHX//vtvmJmZ4VwboFgsxlKpJLVzc3NSd+LECambmZkJ8/Pz5z3XpNHp6OgIDzzwgNQePHhQ6gYGBqSuUqlIHdIVCoVQLpeldvfu3VI3OTkpdX19fVKHdKVSSf79GhwclLp9+/ZJXX9//4qP8fEKgBWjA8CK0QFgxegAsGJ0AFgxOgCsGB0AVowOAKukiwMvu+yy8Pjjj0vt7bffLnW7du2SuqGhIalDunK5LF9E9vvvv0vdsWPHpK65uVnqkO7IkSPyv+/HH38sdV999ZXUVavVFR/jnQ4AK0YHgBWjA8CK0QFgxegAsGJ0AFgxOgCsGB0AVowOAKukK5LHx8fD66+/LrWvvvqq1O3fv1/qvvvuO6lDuqGhoXDXXXdJ7Q8//CB16pXLaJxSqRRefPFFqVWvSFfvkVwP73QAWDE6AKwYHQBWjA4AK0YHgBWjA8CK0QFgxegAsGJ0AFgxOgCsshijHmfZRAhhpHEvp67eGGP3BXruNY1zXZsu1nNNGh0AWC0+XgGwYnQAWDE6AKwYHQBWSTfx2rBhQ9y4caPU/vrrr1LX1tYmdfPz82FxcTGTYiQpFouxVCpJ7W+//SZ1uZz2ozU7Oxvm5+c51wbIskz+K9F1110ndaOjo1I3MzMT5ubmznuuSaOzcePG8O6770rtLbfcInVbtmyRuqNHj0od0pVKJfnOcbfddpvUdXZ2St0XX3whdWiszz77TOqeeeYZqfv0009XfIyPVwCsGB0AVowOACtGB4AVowPAitEBYMXoALBidABYJV0cODIyEh555BGpVS8i2rlzp9Q9/PDDUod0y8vLYXp6WmqfffZZqevr65O6Wq0mdUi3detW+aLPhYUFqXvqqaek7siRIys+xjsdAFaMDgArRgeAFaMDwIrRAWDF6ACwYnQAWDE6AKwYHQBWSVckt7S0hM2bN0vt/v37pU6952o+n5c6pDt69Gjo6OiQ2j179kjdrl27pO6XX36ROqT7+eefQ7lcltr169dL3Ycffih1TU1NKz7GOx0AVowOACtGB4AVowPAitEBYMXoALBidABYMToArBgdAFaMDgCrLMaox1k2EUIYadzLqas3xth9gZ57TeNc16aL9VyTRgcAVouPVwCsGB0AVowOACtGB4BV0k288vl8bG5ultrZ2VmpU79WNsYYYoyZFCNJlmXyXxNyOe1H5vrrr5e64eHhMDk5ybk2QC6Xi+rN75aWlqRucXFRfv6Vfl+TRqe5uTnceOONUlvvu4zPVa1WpU79R0FjdXV1SZ36HdqVSmU1Lwd15PP5cM0110jtxMSE1I2Nja3mJYUQ+HgFwIzRAWDF6ACwYnQAWDE6AKwYHQBWjA4AK0YHgFXSxYFnzpwJhw4dktpHH31U6l577TWpu/XWW6UO6bq6usKOHTuk9qabbpK6N954Q+rGx8elDv8d9dY16td7Hzt2TOruu+++FR/jnQ4AK0YHgBWjA8CK0QFgxegAsGJ0AFgxOgCsGB0AVowOAKukK5Ivv/zycP/990utekVya2ur1K1bxz42SldXV90rSM/11ltvSd3zzz8vdQcOHJA6pFteXg5TU1NSu337dql75513pK7evbT5TQZgxegAsGJ0AFgxOgCsGB0AVowOACtGB4AVowPAitEBYMXoALDK1Bs3hxBClmUTIYSRxr2cunpjjN0X6LnXNM51bbpYzzVpdABgtfh4BcCK0QFgxegAsGJ0AFgxOgCsku4c2NbWFjs7O6V2cXFR6jZs2CB1J0+eDFNTU5kUI0k+n4/qHRzVc1X/KrqwsBCWlpY41wZob2+PxWJRaguFgtTVajWpGx8fX/H3NWl0Ojs7w549e6T2xIkTUrdz506pe+yxx6QO6VpbW8O2bduk9q+//pI6dZwGBwelDumKxWLYt2+f1F511VVSNzc3J3X1doKPVwCsGB0AVowOACtGB4AVowPAitEBYMXoALBidABYJd1Pp6WlJaoXER08eFDqNm3aJD9/jJErVxugqakpXnLJJVJ7ww03SN0TTzwhdU8++WQ4fvw459oAlUolDgwMSO2bb74pdV9//bXU9ff3h3/++ee858o7HQBWjA4AK0YHgBWjA8CK0QFgxegAsGJ0AFgxOgCsGB0AVkm3K63VaqFarUrt1VdfLXUffPCB1D333HNSh3S1Wi1MT09L7eeffy5133zzjdTlckk/gkiwsLAQ/vzzT6kdHR2Vuo8++mg1LymEwDsdAGaMDgArRgeAFaMDwIrRAWDF6ACwYnQAWDE6AKwYHQBWjA4Aq6Qbs2dZNhFCGGncy6mrN8bYfYGee03jXNemi/Vck0YHAFaLj1cArBgdAFaMDgArRgeAVdIdlIrFYuzt7ZXaM2fOSN3x48fl5+drhRsjy7KYZdo/7bp12v+ntmzZInXDw8NhcnKSc22AYrEYS6XS//S/OTExIXWnTp0K1Wr1vOeaNDq9vb3h22+/ldrDhw9L3R133JHyEtAAWZaF5uZmqc3n81Knfod2pVKROqQrlUryOagOHDggdS+99NKKj/HxCoAVowPAitEBYMXoALBidABYMToArBgdAFaMDgCrpIsDR0dHw9NPPy21d955p9SNjY1J3fbt26UO6WKM4ezZs1I7ODgodS+//LLUnTx5UuqQbmxsLOzdu1dqd+zYIXWffPKJ1J0+fXrFx3inA8CK0QFgxegAsGJ0AFgxOgCsGB0AVowOACtGB4AVowPAKumK5J6entDX1ye16j2S3377bak7deqU1CHdlVdeGV544QWpfe+996RueXlZ6mq1mtQh3RVXXFH3tqHneuWVV6Suv79/NS8phMA7HQBmjA4AK0YHgBWjA8CK0QFgxegAsGJ0AFgxOgCsGB0AVowOAKssxqjHWTYRQhhp3MupqzfG2H2BnntN41zXpov1XJNGBwBWi49XAKwYHQBWjA4AK0YHgFXSTbxaWlpie3u71La1tUnd8PCw/PwxxkyOIcvlcrFQKEjt7Oys1DU1NUldrVYLtVqNc22ASy+9NPb09Ejt33//LXXqTdempqbC2bNnz3uuSaPT3t4e7r33XqndunWr1D300EMpLwENUCgUQrlcltrvv/9e6tavXy9109PTUod0PT094fDhw1Kr3hF0ZmZG6t5///0VH+PjFQArRgeAFaMDwIrRAWDF6ACwYnQAWDE6AKwYHQBWSRcHLiwshD/++ENqv/zyS6m7+eabpe7HH3+UOqQrl8thYGBAavfu3fs/7bZt2yZ1SPfTTz+FTZs2Sa36td3ValXqDh06tOJjvNMBYMXoALBidABYMToArBgdAFaMDgArRgeAFaMDwIrRAWCVdEVyV1dXuPvuu6V2aWlJ6h588EGpq1QqUod0i4uLYXx8XGp3794tdffcc4/UDQ0NSR3SXXvttXWvDD5Xlmm3qe7v75e6elcu804HgBWjA8CK0QFgxegAsGJ0AFgxOgCsGB0AVowOACtGB4AVowPAKosx6nGWTYQQRhr3curqjTF2X6DnXtM417XpYj3XpNEBgNXi4xUAK0YHgBWjA8CK0QFgxegAsGJ0AFgxOgCsGB0AVowOAKv/AOYu21TSkmpBAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Last layer filters\")\n",
        "    last_filters = model.get_last_conv_layer_filters()\n",
        "    print_filter(last_filters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "RYjeVJRkKg1D",
        "outputId": "20800a17-ec17-44af-c733-6bd4e6f8c704"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last layer filters\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 18 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let see what the graph look like with those filter"
      ],
      "metadata": {
        "id": "WHEW5UQdKhw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Fin output size\n",
        "    img, label = train_technical_analysis_dataset.__getitem__(0)\n",
        "    # vis_image = img.permute(1, 2, 0)\n",
        "    vis_image = img\n",
        "    channel, dim_x_img, dim_y_img = vis_image.shape\n",
        "    dim_out = (dim_x_img-3)//1 + 1\n",
        "\n",
        "    output = np.zeros((64, dim_out, dim_out))\n",
        "\n",
        "    for filter_idx in range(first_filters.shape[0]):\n",
        "        filter = first_filters[filter_idx]\n",
        "\n",
        "        for channel_i in range(filter.shape[0]):\n",
        "            # Apply kernel\n",
        "            kernel = filter[channel_i]\n",
        "            img = vis_image[channel_i].numpy()\n",
        "            for i in range(0, dim_out):\n",
        "                for j in range(0, dim_out):\n",
        "                    # Select part of the img\n",
        "                    img_patch = img[i:i+3, j:j+3]\n",
        "                    # Apply kernel\n",
        "                    kernel_output = np.multiply(img_patch, kernel)\n",
        "                    kernel_output = np.sum(kernel_output)\n",
        "                    # Save output\n",
        "                    output[filter_idx, i, j] = kernel_output\n",
        "\n",
        "    from matplotlib.pyplot import figure\n",
        "    figure(figsize=(10,10))\n",
        "\n",
        "    ax = [plt.subplot(8,8,i+1) for i in range(64)]\n",
        "\n",
        "    for i, a in enumerate(ax):\n",
        "        a.set_xticks([])\n",
        "        a.set_yticks([])\n",
        "\n",
        "        a.imshow(output[i,:,:], cmap='gray')\n",
        "\n",
        "    plt.subplots_adjust(wspace=0., hspace=0.1)\n"
      ],
      "metadata": {
        "id": "KsR40u58KWYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last layer"
      ],
      "metadata": {
        "id": "9fQXFdM0KYvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    model_extract_last_features = create_feature_extractor(model, {\"layer4\": \"layer4\"})\n",
        "    out = model_extract_last_features(vis_image.to(device))\n",
        "    out['layer4'].shape\n",
        "\n",
        "    figure(figsize=(10,10))\n",
        "\n",
        "    ax = [plt.subplot(8,8,i+1) for i in range(64)]\n",
        "\n",
        "    for i, a in enumerate(ax):\n",
        "        a.set_xticks([])\n",
        "        a.set_yticks([])\n",
        "\n",
        "        image = out['layer4'].cpu().detach().numpy()[0, i,:,:]\n",
        "        a.imshow(image, cmap='gray')\n",
        "\n",
        "    plt.subplots_adjust(wspace=0., hspace=0.1)"
      ],
      "metadata": {
        "id": "Ny6RkagGKYR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ViT"
      ],
      "metadata": {
        "id": "Alc2VeOhlRz-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xu9sqc08lTji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's trade some stock and loose money, but in style hehe"
      ],
      "metadata": {
        "id": "HGfi9001Krot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "zK2F0__TKyZ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}